{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ravdess_preprocessed_cnn1d.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HrithikBT/Emotion_Analysis/blob/master/ravdess_preprocessed_cnn1d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwpj7YmH8HOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -q pysoundfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNZd49he8Ogm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -q librosa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9FEH7IN8OlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -q h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PedUTjU49lfz",
        "colab_type": "code",
        "outputId": "6a10cd68-904e-4227-d688-980341c36ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAepyyQx8OeD",
        "colab_type": "code",
        "outputId": "8f8e3615-0352-4df5-c4dd-e34d202ebdf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import soundfile # to read audio file\n",
        "import numpy as np\n",
        "import librosa # to extract speech features\n",
        "import glob\n",
        "import os\n",
        "import pickle # to save model after training\n",
        "from sklearn.model_selection import train_test_split # for splitting training and testing\n",
        "from sklearn.neural_network import MLPClassifier # multi-layer perceptron model\n",
        "from sklearn.metrics import accuracy_score # to measure how good we are\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.layers import Activation, Dense,Conv1D,Dropout,MaxPooling1D,Flatten\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZEsNRTh8S-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_feature(file_name, **kwargs):\n",
        "    \"\"\"\n",
        "    Extract feature from audio file `file_name`\n",
        "        Features supported:\n",
        "            - MFCC (mfcc)\n",
        "            - Chroma (chroma)\n",
        "            - MEL Spectrogram Frequency (mel)\n",
        "            - Contrast (contrast)\n",
        "            - Tonnetz (tonnetz)\n",
        "        e.g:\n",
        "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
        "    \"\"\"\n",
        "    mfcc = kwargs.get(\"mfcc\")\n",
        "    chroma = kwargs.get(\"chroma\")\n",
        "    mel = kwargs.get(\"mel\")\n",
        "    contrast = kwargs.get(\"contrast\")\n",
        "    tonnetz = kwargs.get(\"tonnetz\")\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate = sound_file.samplerate\n",
        "        if chroma or contrast:\n",
        "            stft = np.abs(librosa.stft(X))\n",
        "        result = np.array([])\n",
        "        if mfcc:\n",
        "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "            result = np.hstack((result, mfccs))\n",
        "        if chroma:\n",
        "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, chroma))\n",
        "        if mel:\n",
        "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, mel))\n",
        "        if contrast:\n",
        "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, contrast))\n",
        "        if tonnetz:\n",
        "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, tonnetz))\n",
        "    return result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPYH7pZl8XPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # all emotions on RAVDESS dataset\n",
        "    \n",
        "int2emotion = {\n",
        "    \"01\": \"neutral\",\n",
        "    \"02\": \"calm\",\n",
        "    \"03\": \"happy\",\n",
        "    \"04\": \"sad\",\n",
        "    \"05\": \"angry\",\n",
        "    \"06\": \"fearful\",\n",
        "    \"07\": \"disgust\",\n",
        "    \"08\": \"surprised\"\n",
        "}\n",
        "\n",
        "# we allow only these emotions ( feel free to tune this on your need )\n",
        "AVAILABLE_EMOTIONS = {\n",
        "    \"angry\",\n",
        "    \"sad\",\n",
        "    \"neutral\",\n",
        "    \"happy\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmYzCmcG8djG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(test_size=0.2):\n",
        "    X, y = [], []\n",
        "    for file in glob.glob(\"/content/drive/My Drive/data/Actor_*/*.wav\"):\n",
        "        # get the base name of the audio file\n",
        "        basename = os.path.basename(file)\n",
        "        # get the emotion label\n",
        "        emotion = int2emotion[basename.split(\"-\")[2]]\n",
        "        # we allow only AVAILABLE_EMOTIONS we set\n",
        "        if emotion not in AVAILABLE_EMOTIONS:\n",
        "            continue\n",
        "        # extract speech features\n",
        "        features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "        # add to data\n",
        "        X.append(features)\n",
        "        y.append(emotion)\n",
        "    # split the data to training and testing and return it\n",
        "    return train_test_split(np.array(X), y, test_size=test_size, random_state=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP8gVeWl8jAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load RAVDESS dataset, 75% training 25% testing\n",
        "X_train, X_test, y_train, y_test = load_data(test_size=0.25)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GpB-1_r8ndS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lb = LabelEncoder()\n",
        "\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePCrDLJe8rIW",
        "colab_type": "code",
        "outputId": "67cc161d-b769-4032-92fc-f8c3e6733ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# print some details\n",
        "# number of samples in training data\n",
        "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
        "# number of samples in testing data\n",
        "print(\"[+] Number of testing samples:\", X_test.shape[0])\n",
        "# number of features used\n",
        "# this is a vector of features extracted \n",
        "# using extract_features() function\n",
        "print(\"[+] Number of features:\", X_train.shape[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[+] Number of training samples: 504\n",
            "[+] Number of testing samples: 168\n",
            "[+] Number of features: 180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_0FswIE8uR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_traincnn =np.expand_dims(X_train, axis=2)\n",
        "x_testcnn= np.expand_dims(X_test, axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKTxPORk8yXh",
        "colab_type": "code",
        "outputId": "471bf34b-8f7c-4156-d5fb-2645387b1313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(Conv1D(256, 5,padding='same', input_shape=(180,1))) #1\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 5,padding='same')) #2\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Conv1D(128, 5,padding='same')) #3\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Conv1D(128, 5,padding='same')) #4\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Conv1D(128, 5,padding='same')) #5\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Conv1D(128, 5,padding='same')) #6\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4)) #7\n",
        "model.add(Activation('softmax'))\n",
        "opt = keras.optimizers.Adam(lr=0.00001, decay=1e-6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjTGxnqH82gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile Model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmFBaPOG88k4",
        "colab_type": "code",
        "outputId": "acbf733e-e955-4467-f99d-51e957571bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Fit Model\n",
        "import matplotlib.pyplot as plt\n",
        "history = model.fit(np.array(x_traincnn), y_train, batch_size=16, epochs=700, validation_data=(np.array(x_testcnn), y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 504 samples, validate on 168 samples\n",
            "Epoch 1/700\n",
            "504/504 [==============================] - 4s 7ms/sample - loss: 2.0163 - acc: 0.2222 - val_loss: 1.3623 - val_acc: 0.2262\n",
            "Epoch 2/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 1.3802 - acc: 0.3056 - val_loss: 1.3507 - val_acc: 0.2619\n",
            "Epoch 3/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 1.3450 - acc: 0.3393 - val_loss: 1.3204 - val_acc: 0.3274\n",
            "Epoch 4/700\n",
            "504/504 [==============================] - 0s 386us/sample - loss: 1.3270 - acc: 0.3333 - val_loss: 1.2936 - val_acc: 0.3571\n",
            "Epoch 5/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 1.2930 - acc: 0.3730 - val_loss: 1.2488 - val_acc: 0.4107\n",
            "Epoch 6/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 1.2782 - acc: 0.4067 - val_loss: 1.2353 - val_acc: 0.4345\n",
            "Epoch 7/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 1.2712 - acc: 0.4028 - val_loss: 1.2251 - val_acc: 0.4226\n",
            "Epoch 8/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 1.2597 - acc: 0.4127 - val_loss: 1.1942 - val_acc: 0.4524\n",
            "Epoch 9/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 1.2195 - acc: 0.4187 - val_loss: 1.1795 - val_acc: 0.4583\n",
            "Epoch 10/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 1.2043 - acc: 0.4266 - val_loss: 1.1923 - val_acc: 0.4286\n",
            "Epoch 11/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 1.2038 - acc: 0.4405 - val_loss: 1.1642 - val_acc: 0.4583\n",
            "Epoch 12/700\n",
            "504/504 [==============================] - 0s 417us/sample - loss: 1.1932 - acc: 0.4444 - val_loss: 1.1650 - val_acc: 0.4643\n",
            "Epoch 13/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 1.1761 - acc: 0.4742 - val_loss: 1.1473 - val_acc: 0.4762\n",
            "Epoch 14/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 1.1760 - acc: 0.4544 - val_loss: 1.1363 - val_acc: 0.4167\n",
            "Epoch 15/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 1.1678 - acc: 0.4504 - val_loss: 1.1534 - val_acc: 0.4464\n",
            "Epoch 16/700\n",
            "504/504 [==============================] - 0s 416us/sample - loss: 1.1441 - acc: 0.4901 - val_loss: 1.1358 - val_acc: 0.4048\n",
            "Epoch 17/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 1.1439 - acc: 0.4881 - val_loss: 1.1245 - val_acc: 0.4762\n",
            "Epoch 18/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 1.1367 - acc: 0.4921 - val_loss: 1.1296 - val_acc: 0.4226\n",
            "Epoch 19/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 1.1353 - acc: 0.4881 - val_loss: 1.1098 - val_acc: 0.4702\n",
            "Epoch 20/700\n",
            "504/504 [==============================] - 0s 415us/sample - loss: 1.1215 - acc: 0.4901 - val_loss: 1.1047 - val_acc: 0.4881\n",
            "Epoch 21/700\n",
            "504/504 [==============================] - 0s 416us/sample - loss: 1.1213 - acc: 0.4762 - val_loss: 1.1110 - val_acc: 0.4583\n",
            "Epoch 22/700\n",
            "504/504 [==============================] - 0s 410us/sample - loss: 1.1276 - acc: 0.4940 - val_loss: 1.1008 - val_acc: 0.4940\n",
            "Epoch 23/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 1.1144 - acc: 0.5020 - val_loss: 1.1385 - val_acc: 0.4762\n",
            "Epoch 24/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 1.1163 - acc: 0.4802 - val_loss: 1.0987 - val_acc: 0.4702\n",
            "Epoch 25/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 1.1045 - acc: 0.4841 - val_loss: 1.0906 - val_acc: 0.4702\n",
            "Epoch 26/700\n",
            "504/504 [==============================] - 0s 409us/sample - loss: 1.0970 - acc: 0.5020 - val_loss: 1.0934 - val_acc: 0.4583\n",
            "Epoch 27/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 1.0858 - acc: 0.5159 - val_loss: 1.1120 - val_acc: 0.4762\n",
            "Epoch 28/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 1.0855 - acc: 0.5139 - val_loss: 1.0833 - val_acc: 0.4524\n",
            "Epoch 29/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 1.0831 - acc: 0.5139 - val_loss: 1.0861 - val_acc: 0.4702\n",
            "Epoch 30/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 1.0642 - acc: 0.5357 - val_loss: 1.0693 - val_acc: 0.4583\n",
            "Epoch 31/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 1.0719 - acc: 0.5119 - val_loss: 1.0692 - val_acc: 0.4762\n",
            "Epoch 32/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 1.0656 - acc: 0.5218 - val_loss: 1.0716 - val_acc: 0.4821\n",
            "Epoch 33/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 1.0681 - acc: 0.5000 - val_loss: 1.0808 - val_acc: 0.4286\n",
            "Epoch 34/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 1.0672 - acc: 0.5040 - val_loss: 1.0586 - val_acc: 0.4702\n",
            "Epoch 35/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 1.0495 - acc: 0.5317 - val_loss: 1.0750 - val_acc: 0.4583\n",
            "Epoch 36/700\n",
            "504/504 [==============================] - 0s 419us/sample - loss: 1.0324 - acc: 0.5337 - val_loss: 1.0824 - val_acc: 0.4762\n",
            "Epoch 37/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 1.0468 - acc: 0.5198 - val_loss: 1.0483 - val_acc: 0.4881\n",
            "Epoch 38/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 1.0388 - acc: 0.5337 - val_loss: 1.0669 - val_acc: 0.4583\n",
            "Epoch 39/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 1.0316 - acc: 0.5298 - val_loss: 1.0748 - val_acc: 0.4524\n",
            "Epoch 40/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 1.0226 - acc: 0.5337 - val_loss: 1.0452 - val_acc: 0.5119\n",
            "Epoch 41/700\n",
            "504/504 [==============================] - 0s 407us/sample - loss: 1.0438 - acc: 0.5179 - val_loss: 1.0430 - val_acc: 0.4643\n",
            "Epoch 42/700\n",
            "504/504 [==============================] - 0s 410us/sample - loss: 1.0193 - acc: 0.5536 - val_loss: 1.0599 - val_acc: 0.4821\n",
            "Epoch 43/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 1.0237 - acc: 0.5258 - val_loss: 1.0261 - val_acc: 0.5298\n",
            "Epoch 44/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 1.0158 - acc: 0.5198 - val_loss: 1.0692 - val_acc: 0.4345\n",
            "Epoch 45/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 1.0140 - acc: 0.5377 - val_loss: 1.0305 - val_acc: 0.5060\n",
            "Epoch 46/700\n",
            "504/504 [==============================] - 0s 408us/sample - loss: 1.0088 - acc: 0.5258 - val_loss: 1.0345 - val_acc: 0.4821\n",
            "Epoch 47/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.9988 - acc: 0.5437 - val_loss: 1.0375 - val_acc: 0.4881\n",
            "Epoch 48/700\n",
            "504/504 [==============================] - 0s 417us/sample - loss: 1.0013 - acc: 0.5357 - val_loss: 1.0345 - val_acc: 0.5119\n",
            "Epoch 49/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.9974 - acc: 0.5595 - val_loss: 1.0656 - val_acc: 0.4940\n",
            "Epoch 50/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.9874 - acc: 0.5556 - val_loss: 1.0236 - val_acc: 0.4702\n",
            "Epoch 51/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.9817 - acc: 0.5437 - val_loss: 1.0199 - val_acc: 0.5000\n",
            "Epoch 52/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.9903 - acc: 0.5734 - val_loss: 1.0097 - val_acc: 0.5179\n",
            "Epoch 53/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.9805 - acc: 0.5595 - val_loss: 1.0413 - val_acc: 0.4583\n",
            "Epoch 54/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.9817 - acc: 0.5734 - val_loss: 1.0289 - val_acc: 0.5060\n",
            "Epoch 55/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.9631 - acc: 0.5913 - val_loss: 1.0202 - val_acc: 0.4881\n",
            "Epoch 56/700\n",
            "504/504 [==============================] - 0s 409us/sample - loss: 0.9734 - acc: 0.5734 - val_loss: 1.0308 - val_acc: 0.4940\n",
            "Epoch 57/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.9679 - acc: 0.5734 - val_loss: 1.0118 - val_acc: 0.4702\n",
            "Epoch 58/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.9543 - acc: 0.5774 - val_loss: 1.0249 - val_acc: 0.5000\n",
            "Epoch 59/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.9735 - acc: 0.5635 - val_loss: 1.0194 - val_acc: 0.4821\n",
            "Epoch 60/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.9597 - acc: 0.5635 - val_loss: 1.0021 - val_acc: 0.5179\n",
            "Epoch 61/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.9514 - acc: 0.5714 - val_loss: 1.0046 - val_acc: 0.4821\n",
            "Epoch 62/700\n",
            "504/504 [==============================] - 0s 375us/sample - loss: 0.9522 - acc: 0.5615 - val_loss: 1.0195 - val_acc: 0.4821\n",
            "Epoch 63/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.9358 - acc: 0.5893 - val_loss: 1.0161 - val_acc: 0.5119\n",
            "Epoch 64/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.9584 - acc: 0.5595 - val_loss: 1.0015 - val_acc: 0.5060\n",
            "Epoch 65/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.9445 - acc: 0.5794 - val_loss: 0.9939 - val_acc: 0.5060\n",
            "Epoch 66/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.9363 - acc: 0.5992 - val_loss: 1.0209 - val_acc: 0.4940\n",
            "Epoch 67/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.9420 - acc: 0.5774 - val_loss: 0.9823 - val_acc: 0.5476\n",
            "Epoch 68/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.9461 - acc: 0.5635 - val_loss: 0.9866 - val_acc: 0.5417\n",
            "Epoch 69/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.9250 - acc: 0.5833 - val_loss: 0.9722 - val_acc: 0.5595\n",
            "Epoch 70/700\n",
            "504/504 [==============================] - 0s 376us/sample - loss: 0.9158 - acc: 0.6091 - val_loss: 0.9837 - val_acc: 0.5060\n",
            "Epoch 71/700\n",
            "504/504 [==============================] - 0s 417us/sample - loss: 0.9214 - acc: 0.5972 - val_loss: 1.0015 - val_acc: 0.4821\n",
            "Epoch 72/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.9145 - acc: 0.5933 - val_loss: 0.9800 - val_acc: 0.5298\n",
            "Epoch 73/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.9154 - acc: 0.5952 - val_loss: 0.9991 - val_acc: 0.4583\n",
            "Epoch 74/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.9054 - acc: 0.6250 - val_loss: 0.9795 - val_acc: 0.5298\n",
            "Epoch 75/700\n",
            "504/504 [==============================] - 0s 384us/sample - loss: 0.9117 - acc: 0.6111 - val_loss: 0.9935 - val_acc: 0.5238\n",
            "Epoch 76/700\n",
            "504/504 [==============================] - 0s 410us/sample - loss: 0.9250 - acc: 0.5794 - val_loss: 0.9824 - val_acc: 0.5060\n",
            "Epoch 77/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.9069 - acc: 0.6052 - val_loss: 0.9668 - val_acc: 0.5357\n",
            "Epoch 78/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.9006 - acc: 0.6052 - val_loss: 0.9783 - val_acc: 0.5060\n",
            "Epoch 79/700\n",
            "504/504 [==============================] - 0s 383us/sample - loss: 0.8925 - acc: 0.6111 - val_loss: 0.9910 - val_acc: 0.5119\n",
            "Epoch 80/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.9009 - acc: 0.5833 - val_loss: 0.9594 - val_acc: 0.5179\n",
            "Epoch 81/700\n",
            "504/504 [==============================] - 0s 409us/sample - loss: 0.8939 - acc: 0.6052 - val_loss: 0.9777 - val_acc: 0.5179\n",
            "Epoch 82/700\n",
            "504/504 [==============================] - 0s 381us/sample - loss: 0.8995 - acc: 0.5913 - val_loss: 0.9460 - val_acc: 0.5952\n",
            "Epoch 83/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.8891 - acc: 0.6210 - val_loss: 0.9676 - val_acc: 0.5179\n",
            "Epoch 84/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.8999 - acc: 0.6032 - val_loss: 0.9588 - val_acc: 0.5357\n",
            "Epoch 85/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.8856 - acc: 0.6190 - val_loss: 0.9618 - val_acc: 0.5119\n",
            "Epoch 86/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.8808 - acc: 0.6310 - val_loss: 0.9592 - val_acc: 0.5238\n",
            "Epoch 87/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.8724 - acc: 0.6448 - val_loss: 0.9411 - val_acc: 0.5655\n",
            "Epoch 88/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.8750 - acc: 0.6151 - val_loss: 0.9682 - val_acc: 0.5476\n",
            "Epoch 89/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.8812 - acc: 0.6171 - val_loss: 0.9561 - val_acc: 0.5476\n",
            "Epoch 90/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.8680 - acc: 0.6389 - val_loss: 0.9825 - val_acc: 0.5060\n",
            "Epoch 91/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.8707 - acc: 0.6230 - val_loss: 0.9464 - val_acc: 0.5595\n",
            "Epoch 92/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.8596 - acc: 0.6250 - val_loss: 0.9509 - val_acc: 0.5357\n",
            "Epoch 93/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.8517 - acc: 0.6448 - val_loss: 0.9423 - val_acc: 0.5476\n",
            "Epoch 94/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.8607 - acc: 0.6409 - val_loss: 0.9708 - val_acc: 0.5417\n",
            "Epoch 95/700\n",
            "504/504 [==============================] - 0s 378us/sample - loss: 0.8630 - acc: 0.6190 - val_loss: 0.9335 - val_acc: 0.5714\n",
            "Epoch 96/700\n",
            "504/504 [==============================] - 0s 418us/sample - loss: 0.8524 - acc: 0.6389 - val_loss: 0.9456 - val_acc: 0.5298\n",
            "Epoch 97/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.8536 - acc: 0.6448 - val_loss: 0.9538 - val_acc: 0.5238\n",
            "Epoch 98/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.8444 - acc: 0.6250 - val_loss: 0.9389 - val_acc: 0.6071\n",
            "Epoch 99/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.8522 - acc: 0.6488 - val_loss: 0.9796 - val_acc: 0.5298\n",
            "Epoch 100/700\n",
            "504/504 [==============================] - 0s 407us/sample - loss: 0.8374 - acc: 0.6310 - val_loss: 0.9539 - val_acc: 0.5714\n",
            "Epoch 101/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.8299 - acc: 0.6448 - val_loss: 0.9461 - val_acc: 0.5179\n",
            "Epoch 102/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.8334 - acc: 0.6607 - val_loss: 0.9415 - val_acc: 0.5298\n",
            "Epoch 103/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.8454 - acc: 0.6250 - val_loss: 0.9301 - val_acc: 0.5774\n",
            "Epoch 104/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.8261 - acc: 0.6706 - val_loss: 0.9362 - val_acc: 0.5655\n",
            "Epoch 105/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.8164 - acc: 0.6706 - val_loss: 0.9126 - val_acc: 0.5833\n",
            "Epoch 106/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.8149 - acc: 0.6746 - val_loss: 0.9348 - val_acc: 0.5357\n",
            "Epoch 107/700\n",
            "504/504 [==============================] - 0s 377us/sample - loss: 0.8299 - acc: 0.6567 - val_loss: 0.9229 - val_acc: 0.5476\n",
            "Epoch 108/700\n",
            "504/504 [==============================] - 0s 377us/sample - loss: 0.8278 - acc: 0.6468 - val_loss: 0.9602 - val_acc: 0.5417\n",
            "Epoch 109/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.8181 - acc: 0.6528 - val_loss: 0.9305 - val_acc: 0.5655\n",
            "Epoch 110/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.8089 - acc: 0.6488 - val_loss: 0.9252 - val_acc: 0.5476\n",
            "Epoch 111/700\n",
            "504/504 [==============================] - 0s 419us/sample - loss: 0.8085 - acc: 0.6647 - val_loss: 0.9080 - val_acc: 0.5952\n",
            "Epoch 112/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.8096 - acc: 0.6647 - val_loss: 0.9300 - val_acc: 0.5357\n",
            "Epoch 113/700\n",
            "504/504 [==============================] - 0s 381us/sample - loss: 0.8117 - acc: 0.6567 - val_loss: 0.9210 - val_acc: 0.5893\n",
            "Epoch 114/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.8032 - acc: 0.6766 - val_loss: 0.9235 - val_acc: 0.5417\n",
            "Epoch 115/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.7944 - acc: 0.6607 - val_loss: 0.9029 - val_acc: 0.6012\n",
            "Epoch 116/700\n",
            "504/504 [==============================] - 0s 411us/sample - loss: 0.7982 - acc: 0.6706 - val_loss: 0.9396 - val_acc: 0.5476\n",
            "Epoch 117/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.7972 - acc: 0.6806 - val_loss: 0.9102 - val_acc: 0.5774\n",
            "Epoch 118/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.7826 - acc: 0.6825 - val_loss: 0.9170 - val_acc: 0.5714\n",
            "Epoch 119/700\n",
            "504/504 [==============================] - 0s 383us/sample - loss: 0.8093 - acc: 0.6409 - val_loss: 0.9189 - val_acc: 0.5595\n",
            "Epoch 120/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.7916 - acc: 0.6647 - val_loss: 0.9060 - val_acc: 0.6190\n",
            "Epoch 121/700\n",
            "504/504 [==============================] - 0s 416us/sample - loss: 0.7906 - acc: 0.6587 - val_loss: 0.9153 - val_acc: 0.5893\n",
            "Epoch 122/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.7836 - acc: 0.6746 - val_loss: 0.9159 - val_acc: 0.5714\n",
            "Epoch 123/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 0.7839 - acc: 0.6865 - val_loss: 0.9256 - val_acc: 0.5536\n",
            "Epoch 124/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.7731 - acc: 0.6786 - val_loss: 0.9035 - val_acc: 0.5833\n",
            "Epoch 125/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.7775 - acc: 0.6726 - val_loss: 0.8958 - val_acc: 0.5774\n",
            "Epoch 126/700\n",
            "504/504 [==============================] - 0s 409us/sample - loss: 0.7811 - acc: 0.6706 - val_loss: 0.8962 - val_acc: 0.6071\n",
            "Epoch 127/700\n",
            "504/504 [==============================] - 0s 382us/sample - loss: 0.7734 - acc: 0.6944 - val_loss: 0.9479 - val_acc: 0.5417\n",
            "Epoch 128/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.7971 - acc: 0.6468 - val_loss: 0.8800 - val_acc: 0.6131\n",
            "Epoch 129/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.7852 - acc: 0.6647 - val_loss: 0.8848 - val_acc: 0.6131\n",
            "Epoch 130/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.7751 - acc: 0.6667 - val_loss: 0.9020 - val_acc: 0.6250\n",
            "Epoch 131/700\n",
            "504/504 [==============================] - 0s 413us/sample - loss: 0.7706 - acc: 0.6687 - val_loss: 0.8759 - val_acc: 0.6250\n",
            "Epoch 132/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.7728 - acc: 0.6806 - val_loss: 0.8839 - val_acc: 0.6190\n",
            "Epoch 133/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.7739 - acc: 0.6647 - val_loss: 0.8978 - val_acc: 0.5774\n",
            "Epoch 134/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.7584 - acc: 0.6845 - val_loss: 0.8833 - val_acc: 0.6369\n",
            "Epoch 135/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.7681 - acc: 0.6706 - val_loss: 0.8884 - val_acc: 0.6310\n",
            "Epoch 136/700\n",
            "504/504 [==============================] - 0s 413us/sample - loss: 0.7542 - acc: 0.6905 - val_loss: 0.8948 - val_acc: 0.6131\n",
            "Epoch 137/700\n",
            "504/504 [==============================] - 0s 384us/sample - loss: 0.7488 - acc: 0.6845 - val_loss: 0.8859 - val_acc: 0.6310\n",
            "Epoch 138/700\n",
            "504/504 [==============================] - 0s 381us/sample - loss: 0.7565 - acc: 0.6746 - val_loss: 0.8995 - val_acc: 0.5595\n",
            "Epoch 139/700\n",
            "504/504 [==============================] - 0s 418us/sample - loss: 0.7550 - acc: 0.6825 - val_loss: 0.8930 - val_acc: 0.6190\n",
            "Epoch 140/700\n",
            "504/504 [==============================] - 0s 381us/sample - loss: 0.7506 - acc: 0.6925 - val_loss: 0.8714 - val_acc: 0.6548\n",
            "Epoch 141/700\n",
            "504/504 [==============================] - 0s 408us/sample - loss: 0.7476 - acc: 0.6964 - val_loss: 0.8918 - val_acc: 0.5774\n",
            "Epoch 142/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.7409 - acc: 0.7044 - val_loss: 0.8863 - val_acc: 0.6369\n",
            "Epoch 143/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.7350 - acc: 0.7163 - val_loss: 0.8911 - val_acc: 0.6012\n",
            "Epoch 144/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.7370 - acc: 0.6925 - val_loss: 0.8686 - val_acc: 0.6488\n",
            "Epoch 145/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.7361 - acc: 0.6865 - val_loss: 0.8671 - val_acc: 0.6131\n",
            "Epoch 146/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.7456 - acc: 0.6706 - val_loss: 0.8747 - val_acc: 0.6071\n",
            "Epoch 147/700\n",
            "504/504 [==============================] - 0s 408us/sample - loss: 0.7314 - acc: 0.7044 - val_loss: 0.8825 - val_acc: 0.6190\n",
            "Epoch 148/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.7314 - acc: 0.7044 - val_loss: 0.9138 - val_acc: 0.5476\n",
            "Epoch 149/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.7361 - acc: 0.7024 - val_loss: 0.8838 - val_acc: 0.6071\n",
            "Epoch 150/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.7304 - acc: 0.7024 - val_loss: 0.8614 - val_acc: 0.6369\n",
            "Epoch 151/700\n",
            "504/504 [==============================] - 0s 411us/sample - loss: 0.7304 - acc: 0.6964 - val_loss: 0.8803 - val_acc: 0.6012\n",
            "Epoch 152/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.7317 - acc: 0.7143 - val_loss: 0.8761 - val_acc: 0.6190\n",
            "Epoch 153/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.7127 - acc: 0.7183 - val_loss: 0.8873 - val_acc: 0.6310\n",
            "Epoch 154/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.7228 - acc: 0.6964 - val_loss: 0.9175 - val_acc: 0.5774\n",
            "Epoch 155/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.7346 - acc: 0.6825 - val_loss: 0.8704 - val_acc: 0.6131\n",
            "Epoch 156/700\n",
            "504/504 [==============================] - 0s 407us/sample - loss: 0.7186 - acc: 0.6905 - val_loss: 0.8746 - val_acc: 0.6250\n",
            "Epoch 157/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.7100 - acc: 0.7163 - val_loss: 0.8742 - val_acc: 0.6250\n",
            "Epoch 158/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.7103 - acc: 0.7044 - val_loss: 0.8688 - val_acc: 0.5952\n",
            "Epoch 159/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.7095 - acc: 0.7024 - val_loss: 0.8621 - val_acc: 0.6250\n",
            "Epoch 160/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.7096 - acc: 0.7024 - val_loss: 0.8905 - val_acc: 0.6071\n",
            "Epoch 161/700\n",
            "504/504 [==============================] - 0s 417us/sample - loss: 0.7212 - acc: 0.6964 - val_loss: 0.8622 - val_acc: 0.6369\n",
            "Epoch 162/700\n",
            "504/504 [==============================] - 0s 409us/sample - loss: 0.7118 - acc: 0.7004 - val_loss: 0.8667 - val_acc: 0.6429\n",
            "Epoch 163/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.7090 - acc: 0.7024 - val_loss: 0.8713 - val_acc: 0.6190\n",
            "Epoch 164/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.7022 - acc: 0.7143 - val_loss: 0.8782 - val_acc: 0.6369\n",
            "Epoch 165/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.6978 - acc: 0.7024 - val_loss: 0.9051 - val_acc: 0.5893\n",
            "Epoch 166/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.6937 - acc: 0.7123 - val_loss: 0.8671 - val_acc: 0.6310\n",
            "Epoch 167/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.6909 - acc: 0.7341 - val_loss: 0.8646 - val_acc: 0.6131\n",
            "Epoch 168/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.6960 - acc: 0.7004 - val_loss: 0.9081 - val_acc: 0.6131\n",
            "Epoch 169/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.7101 - acc: 0.7063 - val_loss: 0.8980 - val_acc: 0.6012\n",
            "Epoch 170/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.7054 - acc: 0.7183 - val_loss: 0.8753 - val_acc: 0.6548\n",
            "Epoch 171/700\n",
            "504/504 [==============================] - 0s 411us/sample - loss: 0.6886 - acc: 0.7262 - val_loss: 0.8579 - val_acc: 0.6369\n",
            "Epoch 172/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.6900 - acc: 0.7242 - val_loss: 0.8574 - val_acc: 0.6369\n",
            "Epoch 173/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.6870 - acc: 0.7321 - val_loss: 0.8521 - val_acc: 0.6548\n",
            "Epoch 174/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.6797 - acc: 0.7361 - val_loss: 0.8713 - val_acc: 0.6190\n",
            "Epoch 175/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 0.6865 - acc: 0.7302 - val_loss: 0.8599 - val_acc: 0.6369\n",
            "Epoch 176/700\n",
            "504/504 [==============================] - 0s 409us/sample - loss: 0.6839 - acc: 0.7302 - val_loss: 0.8690 - val_acc: 0.6369\n",
            "Epoch 177/700\n",
            "504/504 [==============================] - 0s 386us/sample - loss: 0.6864 - acc: 0.7321 - val_loss: 0.8878 - val_acc: 0.6131\n",
            "Epoch 178/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.6813 - acc: 0.7282 - val_loss: 0.8572 - val_acc: 0.6310\n",
            "Epoch 179/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.6824 - acc: 0.7302 - val_loss: 0.8436 - val_acc: 0.6548\n",
            "Epoch 180/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.6715 - acc: 0.7321 - val_loss: 0.8493 - val_acc: 0.6548\n",
            "Epoch 181/700\n",
            "504/504 [==============================] - 0s 411us/sample - loss: 0.6733 - acc: 0.7361 - val_loss: 0.8617 - val_acc: 0.6310\n",
            "Epoch 182/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.6681 - acc: 0.7421 - val_loss: 0.8962 - val_acc: 0.5655\n",
            "Epoch 183/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.6684 - acc: 0.7202 - val_loss: 0.8542 - val_acc: 0.6548\n",
            "Epoch 184/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.6816 - acc: 0.7282 - val_loss: 0.8379 - val_acc: 0.6548\n",
            "Epoch 185/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.6868 - acc: 0.7202 - val_loss: 0.8649 - val_acc: 0.6250\n",
            "Epoch 186/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.6667 - acc: 0.7282 - val_loss: 0.8344 - val_acc: 0.6667\n",
            "Epoch 187/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.6819 - acc: 0.7302 - val_loss: 0.8566 - val_acc: 0.6548\n",
            "Epoch 188/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.6636 - acc: 0.7282 - val_loss: 0.8491 - val_acc: 0.6429\n",
            "Epoch 189/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.6603 - acc: 0.7321 - val_loss: 0.8295 - val_acc: 0.6607\n",
            "Epoch 190/700\n",
            "504/504 [==============================] - 0s 383us/sample - loss: 0.6595 - acc: 0.7401 - val_loss: 0.8541 - val_acc: 0.6250\n",
            "Epoch 191/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.6801 - acc: 0.7282 - val_loss: 0.8822 - val_acc: 0.6190\n",
            "Epoch 192/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.6568 - acc: 0.7361 - val_loss: 0.8622 - val_acc: 0.6548\n",
            "Epoch 193/700\n",
            "504/504 [==============================] - 0s 408us/sample - loss: 0.6624 - acc: 0.7163 - val_loss: 0.8434 - val_acc: 0.6607\n",
            "Epoch 194/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.6528 - acc: 0.7321 - val_loss: 0.8539 - val_acc: 0.6667\n",
            "Epoch 195/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.6566 - acc: 0.7381 - val_loss: 0.8701 - val_acc: 0.6429\n",
            "Epoch 196/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.6571 - acc: 0.7321 - val_loss: 0.8468 - val_acc: 0.6607\n",
            "Epoch 197/700\n",
            "504/504 [==============================] - 0s 383us/sample - loss: 0.6454 - acc: 0.7460 - val_loss: 0.8840 - val_acc: 0.6369\n",
            "Epoch 198/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.6494 - acc: 0.7540 - val_loss: 0.8416 - val_acc: 0.6667\n",
            "Epoch 199/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.6381 - acc: 0.7520 - val_loss: 0.8397 - val_acc: 0.6607\n",
            "Epoch 200/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.6483 - acc: 0.7500 - val_loss: 0.8342 - val_acc: 0.6667\n",
            "Epoch 201/700\n",
            "504/504 [==============================] - 0s 415us/sample - loss: 0.6433 - acc: 0.7361 - val_loss: 0.8319 - val_acc: 0.6786\n",
            "Epoch 202/700\n",
            "504/504 [==============================] - 0s 384us/sample - loss: 0.6365 - acc: 0.7500 - val_loss: 0.8563 - val_acc: 0.6548\n",
            "Epoch 203/700\n",
            "504/504 [==============================] - 0s 409us/sample - loss: 0.6521 - acc: 0.7460 - val_loss: 0.8573 - val_acc: 0.6429\n",
            "Epoch 204/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.6426 - acc: 0.7321 - val_loss: 0.8683 - val_acc: 0.6429\n",
            "Epoch 205/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.6312 - acc: 0.7639 - val_loss: 0.8758 - val_acc: 0.6488\n",
            "Epoch 206/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.6367 - acc: 0.7778 - val_loss: 0.8596 - val_acc: 0.6607\n",
            "Epoch 207/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.6226 - acc: 0.7401 - val_loss: 0.8343 - val_acc: 0.6667\n",
            "Epoch 208/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.6346 - acc: 0.7242 - val_loss: 0.8359 - val_acc: 0.6667\n",
            "Epoch 209/700\n",
            "504/504 [==============================] - 0s 412us/sample - loss: 0.6453 - acc: 0.7480 - val_loss: 0.8416 - val_acc: 0.6488\n",
            "Epoch 210/700\n",
            "504/504 [==============================] - 0s 383us/sample - loss: 0.6239 - acc: 0.7639 - val_loss: 0.8620 - val_acc: 0.6548\n",
            "Epoch 211/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.6262 - acc: 0.7579 - val_loss: 0.8479 - val_acc: 0.6429\n",
            "Epoch 212/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.6262 - acc: 0.7599 - val_loss: 0.8505 - val_acc: 0.6429\n",
            "Epoch 213/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.6279 - acc: 0.7520 - val_loss: 0.8498 - val_acc: 0.6369\n",
            "Epoch 214/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.6298 - acc: 0.7520 - val_loss: 0.8388 - val_acc: 0.6607\n",
            "Epoch 215/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.6257 - acc: 0.7520 - val_loss: 0.8449 - val_acc: 0.6548\n",
            "Epoch 216/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.6180 - acc: 0.7679 - val_loss: 0.8311 - val_acc: 0.6845\n",
            "Epoch 217/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.6222 - acc: 0.7639 - val_loss: 0.8445 - val_acc: 0.6667\n",
            "Epoch 218/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.6002 - acc: 0.7758 - val_loss: 0.8741 - val_acc: 0.6071\n",
            "Epoch 219/700\n",
            "504/504 [==============================] - 0s 384us/sample - loss: 0.6182 - acc: 0.7579 - val_loss: 0.8241 - val_acc: 0.6726\n",
            "Epoch 220/700\n",
            "504/504 [==============================] - 0s 386us/sample - loss: 0.6152 - acc: 0.7579 - val_loss: 0.8372 - val_acc: 0.6667\n",
            "Epoch 221/700\n",
            "504/504 [==============================] - 0s 417us/sample - loss: 0.6190 - acc: 0.7619 - val_loss: 0.8433 - val_acc: 0.6607\n",
            "Epoch 222/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.6065 - acc: 0.7619 - val_loss: 0.8243 - val_acc: 0.6667\n",
            "Epoch 223/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.6076 - acc: 0.7738 - val_loss: 0.8479 - val_acc: 0.6548\n",
            "Epoch 224/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.6212 - acc: 0.7361 - val_loss: 0.8354 - val_acc: 0.6667\n",
            "Epoch 225/700\n",
            "504/504 [==============================] - 0s 412us/sample - loss: 0.6047 - acc: 0.7659 - val_loss: 0.8413 - val_acc: 0.6667\n",
            "Epoch 226/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.6146 - acc: 0.7639 - val_loss: 0.8194 - val_acc: 0.7024\n",
            "Epoch 227/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.6029 - acc: 0.7738 - val_loss: 0.8331 - val_acc: 0.6607\n",
            "Epoch 228/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.5987 - acc: 0.7520 - val_loss: 0.8218 - val_acc: 0.6786\n",
            "Epoch 229/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.6013 - acc: 0.7659 - val_loss: 0.8264 - val_acc: 0.6488\n",
            "Epoch 230/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.6118 - acc: 0.7540 - val_loss: 0.8257 - val_acc: 0.6726\n",
            "Epoch 231/700\n",
            "504/504 [==============================] - 0s 407us/sample - loss: 0.5917 - acc: 0.7679 - val_loss: 0.8254 - val_acc: 0.6726\n",
            "Epoch 232/700\n",
            "504/504 [==============================] - 0s 383us/sample - loss: 0.6016 - acc: 0.7798 - val_loss: 0.8445 - val_acc: 0.6548\n",
            "Epoch 233/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.6059 - acc: 0.7718 - val_loss: 0.8771 - val_acc: 0.6310\n",
            "Epoch 234/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.5953 - acc: 0.7817 - val_loss: 0.8096 - val_acc: 0.6905\n",
            "Epoch 235/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.5980 - acc: 0.7738 - val_loss: 0.8174 - val_acc: 0.6786\n",
            "Epoch 236/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.5879 - acc: 0.7877 - val_loss: 0.8152 - val_acc: 0.6964\n",
            "Epoch 237/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.5959 - acc: 0.7560 - val_loss: 0.8140 - val_acc: 0.6726\n",
            "Epoch 238/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.5913 - acc: 0.7698 - val_loss: 0.8462 - val_acc: 0.6548\n",
            "Epoch 239/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.5882 - acc: 0.7837 - val_loss: 0.8197 - val_acc: 0.6607\n",
            "Epoch 240/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.5864 - acc: 0.7738 - val_loss: 0.8242 - val_acc: 0.6786\n",
            "Epoch 241/700\n",
            "504/504 [==============================] - 0s 413us/sample - loss: 0.5840 - acc: 0.7877 - val_loss: 0.8376 - val_acc: 0.6548\n",
            "Epoch 242/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.5828 - acc: 0.7659 - val_loss: 0.8333 - val_acc: 0.6726\n",
            "Epoch 243/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.5828 - acc: 0.7877 - val_loss: 0.8392 - val_acc: 0.6786\n",
            "Epoch 244/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.5951 - acc: 0.7718 - val_loss: 0.8383 - val_acc: 0.6786\n",
            "Epoch 245/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.5940 - acc: 0.7897 - val_loss: 0.8400 - val_acc: 0.6667\n",
            "Epoch 246/700\n",
            "504/504 [==============================] - 0s 409us/sample - loss: 0.5843 - acc: 0.7579 - val_loss: 0.8569 - val_acc: 0.6429\n",
            "Epoch 247/700\n",
            "504/504 [==============================] - 0s 382us/sample - loss: 0.5769 - acc: 0.7837 - val_loss: 0.8110 - val_acc: 0.6845\n",
            "Epoch 248/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.5751 - acc: 0.7758 - val_loss: 0.8016 - val_acc: 0.6845\n",
            "Epoch 249/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.5683 - acc: 0.7877 - val_loss: 0.8087 - val_acc: 0.6964\n",
            "Epoch 250/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.5759 - acc: 0.7837 - val_loss: 0.8086 - val_acc: 0.6786\n",
            "Epoch 251/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.5760 - acc: 0.7758 - val_loss: 0.8216 - val_acc: 0.6905\n",
            "Epoch 252/700\n",
            "504/504 [==============================] - 0s 379us/sample - loss: 0.5579 - acc: 0.7897 - val_loss: 0.8291 - val_acc: 0.6726\n",
            "Epoch 253/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.5653 - acc: 0.7897 - val_loss: 0.8608 - val_acc: 0.6310\n",
            "Epoch 254/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.5547 - acc: 0.8016 - val_loss: 0.8020 - val_acc: 0.6964\n",
            "Epoch 255/700\n",
            "504/504 [==============================] - 0s 425us/sample - loss: 0.5547 - acc: 0.7996 - val_loss: 0.8157 - val_acc: 0.6964\n",
            "Epoch 256/700\n",
            "504/504 [==============================] - 0s 407us/sample - loss: 0.5595 - acc: 0.7857 - val_loss: 0.8174 - val_acc: 0.6905\n",
            "Epoch 257/700\n",
            "504/504 [==============================] - 0s 379us/sample - loss: 0.5592 - acc: 0.7917 - val_loss: 0.8357 - val_acc: 0.6726\n",
            "Epoch 258/700\n",
            "504/504 [==============================] - 0s 386us/sample - loss: 0.5567 - acc: 0.7917 - val_loss: 0.8611 - val_acc: 0.6667\n",
            "Epoch 259/700\n",
            "504/504 [==============================] - 0s 411us/sample - loss: 0.5663 - acc: 0.7837 - val_loss: 0.8280 - val_acc: 0.6726\n",
            "Epoch 260/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.5412 - acc: 0.8056 - val_loss: 0.8185 - val_acc: 0.6667\n",
            "Epoch 261/700\n",
            "504/504 [==============================] - 0s 408us/sample - loss: 0.5598 - acc: 0.7897 - val_loss: 0.8067 - val_acc: 0.6726\n",
            "Epoch 262/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.5573 - acc: 0.7817 - val_loss: 0.8044 - val_acc: 0.6905\n",
            "Epoch 263/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.5442 - acc: 0.8056 - val_loss: 0.8270 - val_acc: 0.6786\n",
            "Epoch 264/700\n",
            "504/504 [==============================] - 0s 384us/sample - loss: 0.5473 - acc: 0.8115 - val_loss: 0.8068 - val_acc: 0.6905\n",
            "Epoch 265/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 0.5451 - acc: 0.8036 - val_loss: 0.8530 - val_acc: 0.6667\n",
            "Epoch 266/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.5607 - acc: 0.7976 - val_loss: 0.8175 - val_acc: 0.6726\n",
            "Epoch 267/700\n",
            "504/504 [==============================] - 0s 380us/sample - loss: 0.5366 - acc: 0.8115 - val_loss: 0.8216 - val_acc: 0.6607\n",
            "Epoch 268/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.5511 - acc: 0.8075 - val_loss: 0.8138 - val_acc: 0.6905\n",
            "Epoch 269/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.5461 - acc: 0.8115 - val_loss: 0.8358 - val_acc: 0.6786\n",
            "Epoch 270/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.5502 - acc: 0.7996 - val_loss: 0.8105 - val_acc: 0.7202\n",
            "Epoch 271/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.5405 - acc: 0.8155 - val_loss: 0.8146 - val_acc: 0.6905\n",
            "Epoch 272/700\n",
            "504/504 [==============================] - 0s 383us/sample - loss: 0.5461 - acc: 0.8095 - val_loss: 0.8204 - val_acc: 0.6845\n",
            "Epoch 273/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.5493 - acc: 0.7996 - val_loss: 0.8122 - val_acc: 0.7024\n",
            "Epoch 274/700\n",
            "504/504 [==============================] - 0s 382us/sample - loss: 0.5474 - acc: 0.7857 - val_loss: 0.8160 - val_acc: 0.6905\n",
            "Epoch 275/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.5334 - acc: 0.8115 - val_loss: 0.8147 - val_acc: 0.6607\n",
            "Epoch 276/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 0.5273 - acc: 0.8056 - val_loss: 0.8106 - val_acc: 0.7024\n",
            "Epoch 277/700\n",
            "504/504 [==============================] - 0s 383us/sample - loss: 0.5352 - acc: 0.7917 - val_loss: 0.8171 - val_acc: 0.6726\n",
            "Epoch 278/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.5389 - acc: 0.7917 - val_loss: 0.8039 - val_acc: 0.7321\n",
            "Epoch 279/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.5437 - acc: 0.8016 - val_loss: 0.8041 - val_acc: 0.7143\n",
            "Epoch 280/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.5374 - acc: 0.8036 - val_loss: 0.8136 - val_acc: 0.6905\n",
            "Epoch 281/700\n",
            "504/504 [==============================] - 0s 418us/sample - loss: 0.5274 - acc: 0.8115 - val_loss: 0.8124 - val_acc: 0.7083\n",
            "Epoch 282/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.5289 - acc: 0.8214 - val_loss: 0.8029 - val_acc: 0.6964\n",
            "Epoch 283/700\n",
            "504/504 [==============================] - 0s 407us/sample - loss: 0.5195 - acc: 0.8294 - val_loss: 0.8178 - val_acc: 0.6964\n",
            "Epoch 284/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.5209 - acc: 0.8254 - val_loss: 0.8280 - val_acc: 0.6607\n",
            "Epoch 285/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.5257 - acc: 0.8036 - val_loss: 0.8063 - val_acc: 0.7083\n",
            "Epoch 286/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.5279 - acc: 0.8016 - val_loss: 0.8192 - val_acc: 0.6905\n",
            "Epoch 287/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.5271 - acc: 0.8075 - val_loss: 0.8209 - val_acc: 0.6726\n",
            "Epoch 288/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.5149 - acc: 0.8294 - val_loss: 0.8122 - val_acc: 0.6845\n",
            "Epoch 289/700\n",
            "504/504 [==============================] - 0s 382us/sample - loss: 0.5409 - acc: 0.7798 - val_loss: 0.8014 - val_acc: 0.7202\n",
            "Epoch 290/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.5080 - acc: 0.8115 - val_loss: 0.8354 - val_acc: 0.6548\n",
            "Epoch 291/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.5239 - acc: 0.8234 - val_loss: 0.8098 - val_acc: 0.6964\n",
            "Epoch 292/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.5181 - acc: 0.8075 - val_loss: 0.8119 - val_acc: 0.7083\n",
            "Epoch 293/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.5066 - acc: 0.8294 - val_loss: 0.8076 - val_acc: 0.6726\n",
            "Epoch 294/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.5149 - acc: 0.8175 - val_loss: 0.8089 - val_acc: 0.6905\n",
            "Epoch 295/700\n",
            "504/504 [==============================] - 0s 375us/sample - loss: 0.5133 - acc: 0.8254 - val_loss: 0.8167 - val_acc: 0.6845\n",
            "Epoch 296/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.5150 - acc: 0.8135 - val_loss: 0.8474 - val_acc: 0.6726\n",
            "Epoch 297/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.5050 - acc: 0.8155 - val_loss: 0.7983 - val_acc: 0.7024\n",
            "Epoch 298/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.5035 - acc: 0.8313 - val_loss: 0.7975 - val_acc: 0.7202\n",
            "Epoch 299/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.5177 - acc: 0.8016 - val_loss: 0.8067 - val_acc: 0.6845\n",
            "Epoch 300/700\n",
            "504/504 [==============================] - 0s 424us/sample - loss: 0.5135 - acc: 0.8135 - val_loss: 0.7986 - val_acc: 0.7202\n",
            "Epoch 301/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.4997 - acc: 0.8294 - val_loss: 0.8064 - val_acc: 0.6964\n",
            "Epoch 302/700\n",
            "504/504 [==============================] - 0s 412us/sample - loss: 0.5000 - acc: 0.8214 - val_loss: 0.8132 - val_acc: 0.6964\n",
            "Epoch 303/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.4893 - acc: 0.8254 - val_loss: 0.8080 - val_acc: 0.7083\n",
            "Epoch 304/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.4988 - acc: 0.8214 - val_loss: 0.8148 - val_acc: 0.6964\n",
            "Epoch 305/700\n",
            "504/504 [==============================] - 0s 382us/sample - loss: 0.4997 - acc: 0.8175 - val_loss: 0.8169 - val_acc: 0.6845\n",
            "Epoch 306/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.5093 - acc: 0.8214 - val_loss: 0.8302 - val_acc: 0.6786\n",
            "Epoch 307/700\n",
            "504/504 [==============================] - 0s 408us/sample - loss: 0.4850 - acc: 0.8413 - val_loss: 0.8170 - val_acc: 0.7024\n",
            "Epoch 308/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.4947 - acc: 0.8353 - val_loss: 0.8094 - val_acc: 0.6905\n",
            "Epoch 309/700\n",
            "504/504 [==============================] - 0s 382us/sample - loss: 0.4875 - acc: 0.8274 - val_loss: 0.8051 - val_acc: 0.6786\n",
            "Epoch 310/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.4935 - acc: 0.8393 - val_loss: 0.8160 - val_acc: 0.6667\n",
            "Epoch 311/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.4877 - acc: 0.8373 - val_loss: 0.8005 - val_acc: 0.7143\n",
            "Epoch 312/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.4972 - acc: 0.8333 - val_loss: 0.8342 - val_acc: 0.6429\n",
            "Epoch 313/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.4853 - acc: 0.8214 - val_loss: 0.7989 - val_acc: 0.7143\n",
            "Epoch 314/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.4870 - acc: 0.8353 - val_loss: 0.8027 - val_acc: 0.7024\n",
            "Epoch 315/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.4881 - acc: 0.8472 - val_loss: 0.8028 - val_acc: 0.7083\n",
            "Epoch 316/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.4957 - acc: 0.8234 - val_loss: 0.8013 - val_acc: 0.7143\n",
            "Epoch 317/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.4825 - acc: 0.8274 - val_loss: 0.8483 - val_acc: 0.6548\n",
            "Epoch 318/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.4855 - acc: 0.8333 - val_loss: 0.8071 - val_acc: 0.6667\n",
            "Epoch 319/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.4857 - acc: 0.8433 - val_loss: 0.7996 - val_acc: 0.7262\n",
            "Epoch 320/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.4763 - acc: 0.8413 - val_loss: 0.8067 - val_acc: 0.6845\n",
            "Epoch 321/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.4793 - acc: 0.8353 - val_loss: 0.8305 - val_acc: 0.6607\n",
            "Epoch 322/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 0.4814 - acc: 0.8433 - val_loss: 0.7924 - val_acc: 0.6964\n",
            "Epoch 323/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.4753 - acc: 0.8433 - val_loss: 0.8188 - val_acc: 0.7083\n",
            "Epoch 324/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.4767 - acc: 0.8413 - val_loss: 0.8055 - val_acc: 0.6964\n",
            "Epoch 325/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.4719 - acc: 0.8353 - val_loss: 0.8123 - val_acc: 0.6845\n",
            "Epoch 326/700\n",
            "504/504 [==============================] - 0s 381us/sample - loss: 0.4728 - acc: 0.8353 - val_loss: 0.8115 - val_acc: 0.6726\n",
            "Epoch 327/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.4748 - acc: 0.8254 - val_loss: 0.8232 - val_acc: 0.6488\n",
            "Epoch 328/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.4759 - acc: 0.8373 - val_loss: 0.8240 - val_acc: 0.6429\n",
            "Epoch 329/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.4630 - acc: 0.8472 - val_loss: 0.8039 - val_acc: 0.7202\n",
            "Epoch 330/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.4700 - acc: 0.8492 - val_loss: 0.8104 - val_acc: 0.7262\n",
            "Epoch 331/700\n",
            "504/504 [==============================] - 0s 414us/sample - loss: 0.4722 - acc: 0.8433 - val_loss: 0.7814 - val_acc: 0.7262\n",
            "Epoch 332/700\n",
            "504/504 [==============================] - 0s 414us/sample - loss: 0.4737 - acc: 0.8274 - val_loss: 0.7981 - val_acc: 0.7083\n",
            "Epoch 333/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.4687 - acc: 0.8274 - val_loss: 0.8211 - val_acc: 0.6786\n",
            "Epoch 334/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.4553 - acc: 0.8532 - val_loss: 0.8065 - val_acc: 0.6905\n",
            "Epoch 335/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.4680 - acc: 0.8274 - val_loss: 0.8296 - val_acc: 0.6726\n",
            "Epoch 336/700\n",
            "504/504 [==============================] - 0s 378us/sample - loss: 0.4656 - acc: 0.8492 - val_loss: 0.8075 - val_acc: 0.6845\n",
            "Epoch 337/700\n",
            "504/504 [==============================] - 0s 408us/sample - loss: 0.4664 - acc: 0.8234 - val_loss: 0.8129 - val_acc: 0.6786\n",
            "Epoch 338/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.4740 - acc: 0.8373 - val_loss: 0.8071 - val_acc: 0.6905\n",
            "Epoch 339/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.4573 - acc: 0.8433 - val_loss: 0.7912 - val_acc: 0.7321\n",
            "Epoch 340/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.4649 - acc: 0.8274 - val_loss: 0.8122 - val_acc: 0.7083\n",
            "Epoch 341/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.4532 - acc: 0.8413 - val_loss: 0.8365 - val_acc: 0.6726\n",
            "Epoch 342/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.4476 - acc: 0.8532 - val_loss: 0.8354 - val_acc: 0.6726\n",
            "Epoch 343/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.4560 - acc: 0.8413 - val_loss: 0.7906 - val_acc: 0.7321\n",
            "Epoch 344/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.4639 - acc: 0.8313 - val_loss: 0.8026 - val_acc: 0.7440\n",
            "Epoch 345/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.4546 - acc: 0.8512 - val_loss: 0.7951 - val_acc: 0.7143\n",
            "Epoch 346/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 0.4442 - acc: 0.8512 - val_loss: 0.7919 - val_acc: 0.7024\n",
            "Epoch 347/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.4418 - acc: 0.8492 - val_loss: 0.7997 - val_acc: 0.7262\n",
            "Epoch 348/700\n",
            "504/504 [==============================] - 0s 382us/sample - loss: 0.4386 - acc: 0.8512 - val_loss: 0.7949 - val_acc: 0.7083\n",
            "Epoch 349/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.4407 - acc: 0.8492 - val_loss: 0.8047 - val_acc: 0.7321\n",
            "Epoch 350/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.4389 - acc: 0.8671 - val_loss: 0.8101 - val_acc: 0.6548\n",
            "Epoch 351/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.4382 - acc: 0.8591 - val_loss: 0.7877 - val_acc: 0.7083\n",
            "Epoch 352/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.4294 - acc: 0.8532 - val_loss: 0.8055 - val_acc: 0.7321\n",
            "Epoch 353/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.4401 - acc: 0.8492 - val_loss: 0.8475 - val_acc: 0.6667\n",
            "Epoch 354/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 0.4378 - acc: 0.8512 - val_loss: 0.8100 - val_acc: 0.7321\n",
            "Epoch 355/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.4321 - acc: 0.8413 - val_loss: 0.7985 - val_acc: 0.7202\n",
            "Epoch 356/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 0.4443 - acc: 0.8373 - val_loss: 0.7884 - val_acc: 0.7143\n",
            "Epoch 357/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.4456 - acc: 0.8294 - val_loss: 0.8366 - val_acc: 0.6845\n",
            "Epoch 358/700\n",
            "504/504 [==============================] - 0s 384us/sample - loss: 0.4473 - acc: 0.8452 - val_loss: 0.8252 - val_acc: 0.7024\n",
            "Epoch 359/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.4391 - acc: 0.8512 - val_loss: 0.8257 - val_acc: 0.7083\n",
            "Epoch 360/700\n",
            "504/504 [==============================] - 0s 428us/sample - loss: 0.4337 - acc: 0.8452 - val_loss: 0.7967 - val_acc: 0.6905\n",
            "Epoch 361/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.4355 - acc: 0.8512 - val_loss: 0.8053 - val_acc: 0.7321\n",
            "Epoch 362/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.4319 - acc: 0.8452 - val_loss: 0.8029 - val_acc: 0.7262\n",
            "Epoch 363/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.4208 - acc: 0.8690 - val_loss: 0.8168 - val_acc: 0.7262\n",
            "Epoch 364/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.4307 - acc: 0.8631 - val_loss: 0.8233 - val_acc: 0.6964\n",
            "Epoch 365/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.4337 - acc: 0.8452 - val_loss: 0.8039 - val_acc: 0.7202\n",
            "Epoch 366/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.4312 - acc: 0.8413 - val_loss: 0.8011 - val_acc: 0.6964\n",
            "Epoch 367/700\n",
            "504/504 [==============================] - 0s 410us/sample - loss: 0.4263 - acc: 0.8790 - val_loss: 0.8143 - val_acc: 0.7024\n",
            "Epoch 368/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.4256 - acc: 0.8552 - val_loss: 0.7893 - val_acc: 0.7262\n",
            "Epoch 369/700\n",
            "504/504 [==============================] - 0s 409us/sample - loss: 0.4171 - acc: 0.8611 - val_loss: 0.8063 - val_acc: 0.6905\n",
            "Epoch 370/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.4155 - acc: 0.8829 - val_loss: 0.8044 - val_acc: 0.7321\n",
            "Epoch 371/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.4252 - acc: 0.8651 - val_loss: 0.8023 - val_acc: 0.7262\n",
            "Epoch 372/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.4064 - acc: 0.8810 - val_loss: 0.8070 - val_acc: 0.7321\n",
            "Epoch 373/700\n",
            "504/504 [==============================] - 0s 428us/sample - loss: 0.4118 - acc: 0.8631 - val_loss: 0.7956 - val_acc: 0.7321\n",
            "Epoch 374/700\n",
            "504/504 [==============================] - 0s 408us/sample - loss: 0.4048 - acc: 0.8810 - val_loss: 0.8103 - val_acc: 0.7143\n",
            "Epoch 375/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.4100 - acc: 0.8631 - val_loss: 0.8126 - val_acc: 0.7083\n",
            "Epoch 376/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.4104 - acc: 0.8710 - val_loss: 0.7812 - val_acc: 0.7143\n",
            "Epoch 377/700\n",
            "504/504 [==============================] - 0s 407us/sample - loss: 0.4158 - acc: 0.8512 - val_loss: 0.8006 - val_acc: 0.7024\n",
            "Epoch 378/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.4087 - acc: 0.8631 - val_loss: 0.8127 - val_acc: 0.6845\n",
            "Epoch 379/700\n",
            "504/504 [==============================] - 0s 411us/sample - loss: 0.4192 - acc: 0.8512 - val_loss: 0.7916 - val_acc: 0.7143\n",
            "Epoch 380/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.4028 - acc: 0.8710 - val_loss: 0.7984 - val_acc: 0.7381\n",
            "Epoch 381/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.4011 - acc: 0.8631 - val_loss: 0.7952 - val_acc: 0.7321\n",
            "Epoch 382/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.4076 - acc: 0.8532 - val_loss: 0.8131 - val_acc: 0.7202\n",
            "Epoch 383/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.4148 - acc: 0.8611 - val_loss: 0.8073 - val_acc: 0.7262\n",
            "Epoch 384/700\n",
            "504/504 [==============================] - 0s 426us/sample - loss: 0.4032 - acc: 0.8770 - val_loss: 0.8414 - val_acc: 0.6726\n",
            "Epoch 385/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.3998 - acc: 0.8790 - val_loss: 0.7984 - val_acc: 0.7321\n",
            "Epoch 386/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.4030 - acc: 0.8591 - val_loss: 0.7923 - val_acc: 0.7321\n",
            "Epoch 387/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.4102 - acc: 0.8512 - val_loss: 0.8071 - val_acc: 0.7024\n",
            "Epoch 388/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.4174 - acc: 0.8472 - val_loss: 0.8068 - val_acc: 0.7083\n",
            "Epoch 389/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.4090 - acc: 0.8631 - val_loss: 0.8241 - val_acc: 0.6905\n",
            "Epoch 390/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.4060 - acc: 0.8710 - val_loss: 0.8052 - val_acc: 0.7143\n",
            "Epoch 391/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.3964 - acc: 0.8770 - val_loss: 0.8120 - val_acc: 0.7262\n",
            "Epoch 392/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.3907 - acc: 0.8611 - val_loss: 0.8007 - val_acc: 0.7202\n",
            "Epoch 393/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.3956 - acc: 0.8750 - val_loss: 0.7930 - val_acc: 0.7024\n",
            "Epoch 394/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.3941 - acc: 0.8770 - val_loss: 0.8338 - val_acc: 0.6964\n",
            "Epoch 395/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.3985 - acc: 0.8611 - val_loss: 0.8287 - val_acc: 0.6905\n",
            "Epoch 396/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.4059 - acc: 0.8710 - val_loss: 0.8074 - val_acc: 0.7143\n",
            "Epoch 397/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.3827 - acc: 0.8790 - val_loss: 0.8128 - val_acc: 0.7202\n",
            "Epoch 398/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.3783 - acc: 0.8829 - val_loss: 0.8627 - val_acc: 0.6786\n",
            "Epoch 399/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.3904 - acc: 0.8750 - val_loss: 0.8327 - val_acc: 0.6964\n",
            "Epoch 400/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.3904 - acc: 0.8710 - val_loss: 0.8107 - val_acc: 0.7381\n",
            "Epoch 401/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.3834 - acc: 0.8671 - val_loss: 0.7951 - val_acc: 0.6964\n",
            "Epoch 402/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.3983 - acc: 0.8710 - val_loss: 0.7919 - val_acc: 0.7024\n",
            "Epoch 403/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.3818 - acc: 0.8710 - val_loss: 0.8364 - val_acc: 0.6905\n",
            "Epoch 404/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.3830 - acc: 0.8790 - val_loss: 0.8181 - val_acc: 0.6905\n",
            "Epoch 405/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.3816 - acc: 0.8750 - val_loss: 0.8053 - val_acc: 0.6905\n",
            "Epoch 406/700\n",
            "504/504 [==============================] - 0s 418us/sample - loss: 0.3909 - acc: 0.8671 - val_loss: 0.8003 - val_acc: 0.7143\n",
            "Epoch 407/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.3752 - acc: 0.8829 - val_loss: 0.7974 - val_acc: 0.7321\n",
            "Epoch 408/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.3886 - acc: 0.8750 - val_loss: 0.8040 - val_acc: 0.7024\n",
            "Epoch 409/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.3817 - acc: 0.8611 - val_loss: 0.8014 - val_acc: 0.7083\n",
            "Epoch 410/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.3762 - acc: 0.8651 - val_loss: 0.7975 - val_acc: 0.7024\n",
            "Epoch 411/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.3703 - acc: 0.8829 - val_loss: 0.8204 - val_acc: 0.7024\n",
            "Epoch 412/700\n",
            "504/504 [==============================] - 0s 415us/sample - loss: 0.3674 - acc: 0.8869 - val_loss: 0.7925 - val_acc: 0.7143\n",
            "Epoch 413/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.3689 - acc: 0.8929 - val_loss: 0.8068 - val_acc: 0.7321\n",
            "Epoch 414/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.3750 - acc: 0.8770 - val_loss: 0.7994 - val_acc: 0.7381\n",
            "Epoch 415/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.3795 - acc: 0.8770 - val_loss: 0.8140 - val_acc: 0.7143\n",
            "Epoch 416/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.3658 - acc: 0.8829 - val_loss: 0.8258 - val_acc: 0.6786\n",
            "Epoch 417/700\n",
            "504/504 [==============================] - 0s 415us/sample - loss: 0.3640 - acc: 0.8909 - val_loss: 0.8107 - val_acc: 0.7024\n",
            "Epoch 418/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.3699 - acc: 0.8790 - val_loss: 0.8003 - val_acc: 0.7202\n",
            "Epoch 419/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.3620 - acc: 0.8909 - val_loss: 0.7944 - val_acc: 0.7202\n",
            "Epoch 420/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.3624 - acc: 0.8770 - val_loss: 0.8200 - val_acc: 0.7024\n",
            "Epoch 421/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.3662 - acc: 0.8770 - val_loss: 0.7887 - val_acc: 0.7202\n",
            "Epoch 422/700\n",
            "504/504 [==============================] - 0s 414us/sample - loss: 0.3653 - acc: 0.8849 - val_loss: 0.8078 - val_acc: 0.7143\n",
            "Epoch 423/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.3626 - acc: 0.8889 - val_loss: 0.8159 - val_acc: 0.7202\n",
            "Epoch 424/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.3715 - acc: 0.8829 - val_loss: 0.8008 - val_acc: 0.7321\n",
            "Epoch 425/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.3637 - acc: 0.8810 - val_loss: 0.7928 - val_acc: 0.7143\n",
            "Epoch 426/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.3622 - acc: 0.8948 - val_loss: 0.8202 - val_acc: 0.6905\n",
            "Epoch 427/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.3534 - acc: 0.8869 - val_loss: 0.8240 - val_acc: 0.7083\n",
            "Epoch 428/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.3762 - acc: 0.8829 - val_loss: 0.7985 - val_acc: 0.7381\n",
            "Epoch 429/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.3688 - acc: 0.8671 - val_loss: 0.7907 - val_acc: 0.7202\n",
            "Epoch 430/700\n",
            "504/504 [==============================] - 0s 410us/sample - loss: 0.3528 - acc: 0.9048 - val_loss: 0.8037 - val_acc: 0.7202\n",
            "Epoch 431/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.3536 - acc: 0.8948 - val_loss: 0.8052 - val_acc: 0.6964\n",
            "Epoch 432/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.3543 - acc: 0.8909 - val_loss: 0.8318 - val_acc: 0.6905\n",
            "Epoch 433/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.3641 - acc: 0.8849 - val_loss: 0.8259 - val_acc: 0.6964\n",
            "Epoch 434/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.3474 - acc: 0.9028 - val_loss: 0.7965 - val_acc: 0.6964\n",
            "Epoch 435/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 0.3546 - acc: 0.8929 - val_loss: 0.8020 - val_acc: 0.7321\n",
            "Epoch 436/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.3416 - acc: 0.9067 - val_loss: 0.8110 - val_acc: 0.7381\n",
            "Epoch 437/700\n",
            "504/504 [==============================] - 0s 410us/sample - loss: 0.3495 - acc: 0.8929 - val_loss: 0.7989 - val_acc: 0.6964\n",
            "Epoch 438/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.3537 - acc: 0.8929 - val_loss: 0.8128 - val_acc: 0.7024\n",
            "Epoch 439/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.3536 - acc: 0.8948 - val_loss: 0.8207 - val_acc: 0.7024\n",
            "Epoch 440/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.3482 - acc: 0.8671 - val_loss: 0.8070 - val_acc: 0.7083\n",
            "Epoch 441/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.3367 - acc: 0.8869 - val_loss: 0.8022 - val_acc: 0.7143\n",
            "Epoch 442/700\n",
            "504/504 [==============================] - 0s 419us/sample - loss: 0.3424 - acc: 0.8810 - val_loss: 0.8127 - val_acc: 0.7083\n",
            "Epoch 443/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.3433 - acc: 0.8929 - val_loss: 0.8211 - val_acc: 0.7143\n",
            "Epoch 444/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.3331 - acc: 0.9187 - val_loss: 0.7941 - val_acc: 0.6964\n",
            "Epoch 445/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.3412 - acc: 0.8849 - val_loss: 0.8067 - val_acc: 0.7143\n",
            "Epoch 446/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.3359 - acc: 0.9008 - val_loss: 0.8263 - val_acc: 0.7143\n",
            "Epoch 447/700\n",
            "504/504 [==============================] - 0s 410us/sample - loss: 0.3307 - acc: 0.9087 - val_loss: 0.7976 - val_acc: 0.7083\n",
            "Epoch 448/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.3403 - acc: 0.8988 - val_loss: 0.7958 - val_acc: 0.7024\n",
            "Epoch 449/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.3282 - acc: 0.9067 - val_loss: 0.7879 - val_acc: 0.7381\n",
            "Epoch 450/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.3357 - acc: 0.8988 - val_loss: 0.7927 - val_acc: 0.7143\n",
            "Epoch 451/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.3344 - acc: 0.9008 - val_loss: 0.7973 - val_acc: 0.7381\n",
            "Epoch 452/700\n",
            "504/504 [==============================] - 0s 407us/sample - loss: 0.3347 - acc: 0.9028 - val_loss: 0.7912 - val_acc: 0.7202\n",
            "Epoch 453/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.3342 - acc: 0.8869 - val_loss: 0.8156 - val_acc: 0.7321\n",
            "Epoch 454/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.3332 - acc: 0.8909 - val_loss: 0.8205 - val_acc: 0.7321\n",
            "Epoch 455/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.3314 - acc: 0.9107 - val_loss: 0.8219 - val_acc: 0.7143\n",
            "Epoch 456/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.3275 - acc: 0.8909 - val_loss: 0.8372 - val_acc: 0.7024\n",
            "Epoch 457/700\n",
            "504/504 [==============================] - 0s 409us/sample - loss: 0.3223 - acc: 0.8948 - val_loss: 0.7973 - val_acc: 0.7202\n",
            "Epoch 458/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.3192 - acc: 0.9087 - val_loss: 0.8324 - val_acc: 0.6905\n",
            "Epoch 459/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.3291 - acc: 0.8948 - val_loss: 0.8032 - val_acc: 0.6964\n",
            "Epoch 460/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.3257 - acc: 0.8849 - val_loss: 0.7962 - val_acc: 0.7262\n",
            "Epoch 461/700\n",
            "504/504 [==============================] - 0s 408us/sample - loss: 0.3324 - acc: 0.9028 - val_loss: 0.8081 - val_acc: 0.7321\n",
            "Epoch 462/700\n",
            "504/504 [==============================] - 0s 411us/sample - loss: 0.3248 - acc: 0.9067 - val_loss: 0.8092 - val_acc: 0.7083\n",
            "Epoch 463/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.3147 - acc: 0.9008 - val_loss: 0.8210 - val_acc: 0.6905\n",
            "Epoch 464/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.3143 - acc: 0.9087 - val_loss: 0.8048 - val_acc: 0.7321\n",
            "Epoch 465/700\n",
            "504/504 [==============================] - 0s 382us/sample - loss: 0.3135 - acc: 0.9187 - val_loss: 0.8154 - val_acc: 0.7262\n",
            "Epoch 466/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.3137 - acc: 0.9067 - val_loss: 0.8138 - val_acc: 0.6964\n",
            "Epoch 467/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.3110 - acc: 0.9206 - val_loss: 0.8338 - val_acc: 0.7321\n",
            "Epoch 468/700\n",
            "504/504 [==============================] - 0s 411us/sample - loss: 0.3214 - acc: 0.9127 - val_loss: 0.8156 - val_acc: 0.7321\n",
            "Epoch 469/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.3081 - acc: 0.9087 - val_loss: 0.8196 - val_acc: 0.7381\n",
            "Epoch 470/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.3177 - acc: 0.9008 - val_loss: 0.8294 - val_acc: 0.7262\n",
            "Epoch 471/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.3210 - acc: 0.9087 - val_loss: 0.8529 - val_acc: 0.7143\n",
            "Epoch 472/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.3117 - acc: 0.9226 - val_loss: 0.8034 - val_acc: 0.7143\n",
            "Epoch 473/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.3126 - acc: 0.9067 - val_loss: 0.8123 - val_acc: 0.7143\n",
            "Epoch 474/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.3119 - acc: 0.9167 - val_loss: 0.8104 - val_acc: 0.7202\n",
            "Epoch 475/700\n",
            "504/504 [==============================] - 0s 377us/sample - loss: 0.3085 - acc: 0.8909 - val_loss: 0.8050 - val_acc: 0.7143\n",
            "Epoch 476/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.3208 - acc: 0.8889 - val_loss: 0.8186 - val_acc: 0.7202\n",
            "Epoch 477/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 0.2953 - acc: 0.9127 - val_loss: 0.8501 - val_acc: 0.6964\n",
            "Epoch 478/700\n",
            "504/504 [==============================] - 0s 409us/sample - loss: 0.3167 - acc: 0.8909 - val_loss: 0.8195 - val_acc: 0.7202\n",
            "Epoch 479/700\n",
            "504/504 [==============================] - 0s 381us/sample - loss: 0.3050 - acc: 0.9286 - val_loss: 0.8225 - val_acc: 0.7083\n",
            "Epoch 480/700\n",
            "504/504 [==============================] - 0s 412us/sample - loss: 0.3110 - acc: 0.9067 - val_loss: 0.8095 - val_acc: 0.7024\n",
            "Epoch 481/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.3126 - acc: 0.9067 - val_loss: 0.8084 - val_acc: 0.7024\n",
            "Epoch 482/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.3063 - acc: 0.9107 - val_loss: 0.8050 - val_acc: 0.7024\n",
            "Epoch 483/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.2876 - acc: 0.9127 - val_loss: 0.8061 - val_acc: 0.7083\n",
            "Epoch 484/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.3085 - acc: 0.8988 - val_loss: 0.7731 - val_acc: 0.7083\n",
            "Epoch 485/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.3043 - acc: 0.9067 - val_loss: 0.7776 - val_acc: 0.7262\n",
            "Epoch 486/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.2870 - acc: 0.9167 - val_loss: 0.7677 - val_acc: 0.7202\n",
            "Epoch 487/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.2961 - acc: 0.9167 - val_loss: 0.7815 - val_acc: 0.7024\n",
            "Epoch 488/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.2858 - acc: 0.9325 - val_loss: 0.8013 - val_acc: 0.7143\n",
            "Epoch 489/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.2963 - acc: 0.9246 - val_loss: 0.7908 - val_acc: 0.7083\n",
            "Epoch 490/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.2962 - acc: 0.9167 - val_loss: 0.8092 - val_acc: 0.7024\n",
            "Epoch 491/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.2907 - acc: 0.9187 - val_loss: 0.8118 - val_acc: 0.7143\n",
            "Epoch 492/700\n",
            "504/504 [==============================] - 0s 417us/sample - loss: 0.2897 - acc: 0.9246 - val_loss: 0.7950 - val_acc: 0.7143\n",
            "Epoch 493/700\n",
            "504/504 [==============================] - 0s 383us/sample - loss: 0.2855 - acc: 0.9286 - val_loss: 0.8085 - val_acc: 0.6905\n",
            "Epoch 494/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.2984 - acc: 0.9107 - val_loss: 0.8399 - val_acc: 0.6905\n",
            "Epoch 495/700\n",
            "504/504 [==============================] - 0s 381us/sample - loss: 0.2868 - acc: 0.9087 - val_loss: 0.8179 - val_acc: 0.7202\n",
            "Epoch 496/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.2923 - acc: 0.9286 - val_loss: 0.8105 - val_acc: 0.7321\n",
            "Epoch 497/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.3005 - acc: 0.9127 - val_loss: 0.8258 - val_acc: 0.7381\n",
            "Epoch 498/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.2848 - acc: 0.9286 - val_loss: 0.8380 - val_acc: 0.6964\n",
            "Epoch 499/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.2854 - acc: 0.9226 - val_loss: 0.8081 - val_acc: 0.7381\n",
            "Epoch 500/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.2963 - acc: 0.9107 - val_loss: 0.7973 - val_acc: 0.7083\n",
            "Epoch 501/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.2901 - acc: 0.9107 - val_loss: 0.8217 - val_acc: 0.7202\n",
            "Epoch 502/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.2765 - acc: 0.9266 - val_loss: 0.8260 - val_acc: 0.7024\n",
            "Epoch 503/700\n",
            "504/504 [==============================] - 0s 372us/sample - loss: 0.2801 - acc: 0.9345 - val_loss: 0.8034 - val_acc: 0.7083\n",
            "Epoch 504/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.2778 - acc: 0.9266 - val_loss: 0.8134 - val_acc: 0.7381\n",
            "Epoch 505/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.2783 - acc: 0.9226 - val_loss: 0.8041 - val_acc: 0.7381\n",
            "Epoch 506/700\n",
            "504/504 [==============================] - 0s 384us/sample - loss: 0.2779 - acc: 0.9286 - val_loss: 0.8163 - val_acc: 0.7202\n",
            "Epoch 507/700\n",
            "504/504 [==============================] - 0s 420us/sample - loss: 0.2784 - acc: 0.9306 - val_loss: 0.8022 - val_acc: 0.7202\n",
            "Epoch 508/700\n",
            "504/504 [==============================] - 0s 407us/sample - loss: 0.2663 - acc: 0.9226 - val_loss: 0.8032 - val_acc: 0.7321\n",
            "Epoch 509/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.2747 - acc: 0.9306 - val_loss: 0.8264 - val_acc: 0.7440\n",
            "Epoch 510/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.2740 - acc: 0.9325 - val_loss: 0.8445 - val_acc: 0.7024\n",
            "Epoch 511/700\n",
            "504/504 [==============================] - 0s 386us/sample - loss: 0.2804 - acc: 0.9167 - val_loss: 0.8346 - val_acc: 0.6964\n",
            "Epoch 512/700\n",
            "504/504 [==============================] - 0s 386us/sample - loss: 0.2819 - acc: 0.9226 - val_loss: 0.8110 - val_acc: 0.7321\n",
            "Epoch 513/700\n",
            "504/504 [==============================] - 0s 386us/sample - loss: 0.2613 - acc: 0.9286 - val_loss: 0.8278 - val_acc: 0.7143\n",
            "Epoch 514/700\n",
            "504/504 [==============================] - 0s 381us/sample - loss: 0.2738 - acc: 0.9306 - val_loss: 0.8243 - val_acc: 0.7440\n",
            "Epoch 515/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.2764 - acc: 0.9246 - val_loss: 0.8288 - val_acc: 0.7321\n",
            "Epoch 516/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.2716 - acc: 0.9306 - val_loss: 0.8057 - val_acc: 0.7202\n",
            "Epoch 517/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.2745 - acc: 0.9266 - val_loss: 0.8203 - val_acc: 0.7262\n",
            "Epoch 518/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.2753 - acc: 0.9246 - val_loss: 0.8108 - val_acc: 0.7262\n",
            "Epoch 519/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.2626 - acc: 0.9444 - val_loss: 0.8133 - val_acc: 0.7202\n",
            "Epoch 520/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.2777 - acc: 0.9127 - val_loss: 0.8279 - val_acc: 0.7143\n",
            "Epoch 521/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.2634 - acc: 0.9405 - val_loss: 0.8139 - val_acc: 0.7202\n",
            "Epoch 522/700\n",
            "504/504 [==============================] - 0s 408us/sample - loss: 0.2623 - acc: 0.9425 - val_loss: 0.8330 - val_acc: 0.7262\n",
            "Epoch 523/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.2760 - acc: 0.9345 - val_loss: 0.8416 - val_acc: 0.7381\n",
            "Epoch 524/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.2820 - acc: 0.9246 - val_loss: 0.8151 - val_acc: 0.7143\n",
            "Epoch 525/700\n",
            "504/504 [==============================] - 0s 383us/sample - loss: 0.2697 - acc: 0.9246 - val_loss: 0.8347 - val_acc: 0.7321\n",
            "Epoch 526/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.2607 - acc: 0.9325 - val_loss: 0.8370 - val_acc: 0.7202\n",
            "Epoch 527/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.2581 - acc: 0.9345 - val_loss: 0.8306 - val_acc: 0.7262\n",
            "Epoch 528/700\n",
            "504/504 [==============================] - 0s 384us/sample - loss: 0.2660 - acc: 0.9286 - val_loss: 0.8067 - val_acc: 0.7381\n",
            "Epoch 529/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.2629 - acc: 0.9365 - val_loss: 0.8083 - val_acc: 0.7262\n",
            "Epoch 530/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.2535 - acc: 0.9425 - val_loss: 0.8074 - val_acc: 0.7381\n",
            "Epoch 531/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.2526 - acc: 0.9484 - val_loss: 0.8039 - val_acc: 0.7440\n",
            "Epoch 532/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 0.2583 - acc: 0.9385 - val_loss: 0.8232 - val_acc: 0.7143\n",
            "Epoch 533/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.2556 - acc: 0.9286 - val_loss: 0.8293 - val_acc: 0.7143\n",
            "Epoch 534/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.2509 - acc: 0.9306 - val_loss: 0.8225 - val_acc: 0.7143\n",
            "Epoch 535/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.2478 - acc: 0.9484 - val_loss: 0.8276 - val_acc: 0.7381\n",
            "Epoch 536/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.2523 - acc: 0.9484 - val_loss: 0.8325 - val_acc: 0.7202\n",
            "Epoch 537/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.2553 - acc: 0.9325 - val_loss: 0.8293 - val_acc: 0.7321\n",
            "Epoch 538/700\n",
            "504/504 [==============================] - 0s 408us/sample - loss: 0.2509 - acc: 0.9425 - val_loss: 0.8401 - val_acc: 0.7500\n",
            "Epoch 539/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.2553 - acc: 0.9306 - val_loss: 0.8223 - val_acc: 0.7262\n",
            "Epoch 540/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.2469 - acc: 0.9325 - val_loss: 0.8241 - val_acc: 0.7381\n",
            "Epoch 541/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.2474 - acc: 0.9464 - val_loss: 0.8235 - val_acc: 0.7381\n",
            "Epoch 542/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.2461 - acc: 0.9345 - val_loss: 0.8204 - val_acc: 0.7202\n",
            "Epoch 543/700\n",
            "504/504 [==============================] - 0s 386us/sample - loss: 0.2533 - acc: 0.9444 - val_loss: 0.8588 - val_acc: 0.7262\n",
            "Epoch 544/700\n",
            "504/504 [==============================] - 0s 382us/sample - loss: 0.2459 - acc: 0.9425 - val_loss: 0.8245 - val_acc: 0.7321\n",
            "Epoch 545/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.2497 - acc: 0.9345 - val_loss: 0.8398 - val_acc: 0.7440\n",
            "Epoch 546/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.2502 - acc: 0.9365 - val_loss: 0.8551 - val_acc: 0.7083\n",
            "Epoch 547/700\n",
            "504/504 [==============================] - 0s 418us/sample - loss: 0.2538 - acc: 0.9345 - val_loss: 0.8415 - val_acc: 0.7381\n",
            "Epoch 548/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.2530 - acc: 0.9365 - val_loss: 0.8763 - val_acc: 0.7202\n",
            "Epoch 549/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.2477 - acc: 0.9444 - val_loss: 0.8420 - val_acc: 0.7143\n",
            "Epoch 550/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.2640 - acc: 0.9206 - val_loss: 0.8326 - val_acc: 0.7262\n",
            "Epoch 551/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 0.2387 - acc: 0.9504 - val_loss: 0.8385 - val_acc: 0.7202\n",
            "Epoch 552/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.2294 - acc: 0.9603 - val_loss: 0.8584 - val_acc: 0.7143\n",
            "Epoch 553/700\n",
            "504/504 [==============================] - 0s 416us/sample - loss: 0.2403 - acc: 0.9425 - val_loss: 0.8297 - val_acc: 0.7262\n",
            "Epoch 554/700\n",
            "504/504 [==============================] - 0s 383us/sample - loss: 0.2267 - acc: 0.9484 - val_loss: 0.8237 - val_acc: 0.7262\n",
            "Epoch 555/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.2325 - acc: 0.9484 - val_loss: 0.8775 - val_acc: 0.6964\n",
            "Epoch 556/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.2347 - acc: 0.9484 - val_loss: 0.8401 - val_acc: 0.7321\n",
            "Epoch 557/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.2335 - acc: 0.9405 - val_loss: 0.8490 - val_acc: 0.7262\n",
            "Epoch 558/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.2287 - acc: 0.9504 - val_loss: 0.8426 - val_acc: 0.7262\n",
            "Epoch 559/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.2367 - acc: 0.9444 - val_loss: 0.8442 - val_acc: 0.7440\n",
            "Epoch 560/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.2436 - acc: 0.9385 - val_loss: 0.8264 - val_acc: 0.7202\n",
            "Epoch 561/700\n",
            "504/504 [==============================] - 0s 405us/sample - loss: 0.2304 - acc: 0.9563 - val_loss: 0.8527 - val_acc: 0.7143\n",
            "Epoch 562/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.2245 - acc: 0.9544 - val_loss: 0.8340 - val_acc: 0.7440\n",
            "Epoch 563/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.2266 - acc: 0.9484 - val_loss: 0.8580 - val_acc: 0.7202\n",
            "Epoch 564/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.2354 - acc: 0.9405 - val_loss: 0.8321 - val_acc: 0.7321\n",
            "Epoch 565/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.2247 - acc: 0.9405 - val_loss: 0.8449 - val_acc: 0.7262\n",
            "Epoch 566/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.2312 - acc: 0.9405 - val_loss: 0.8211 - val_acc: 0.7321\n",
            "Epoch 567/700\n",
            "504/504 [==============================] - 0s 415us/sample - loss: 0.2220 - acc: 0.9484 - val_loss: 0.8443 - val_acc: 0.7202\n",
            "Epoch 568/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.2459 - acc: 0.9306 - val_loss: 0.8332 - val_acc: 0.7202\n",
            "Epoch 569/700\n",
            "504/504 [==============================] - 0s 380us/sample - loss: 0.2194 - acc: 0.9583 - val_loss: 0.8452 - val_acc: 0.7083\n",
            "Epoch 570/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.2312 - acc: 0.9365 - val_loss: 0.8671 - val_acc: 0.7381\n",
            "Epoch 571/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.2263 - acc: 0.9405 - val_loss: 0.8360 - val_acc: 0.7381\n",
            "Epoch 572/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.2253 - acc: 0.9365 - val_loss: 0.8351 - val_acc: 0.7202\n",
            "Epoch 573/700\n",
            "504/504 [==============================] - 0s 384us/sample - loss: 0.2291 - acc: 0.9425 - val_loss: 0.8320 - val_acc: 0.7083\n",
            "Epoch 574/700\n",
            "504/504 [==============================] - 0s 384us/sample - loss: 0.2278 - acc: 0.9464 - val_loss: 0.8274 - val_acc: 0.7262\n",
            "Epoch 575/700\n",
            "504/504 [==============================] - 0s 384us/sample - loss: 0.2205 - acc: 0.9444 - val_loss: 0.8544 - val_acc: 0.7321\n",
            "Epoch 576/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.2188 - acc: 0.9504 - val_loss: 0.8380 - val_acc: 0.7262\n",
            "Epoch 577/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.2262 - acc: 0.9444 - val_loss: 0.8523 - val_acc: 0.7440\n",
            "Epoch 578/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.2196 - acc: 0.9464 - val_loss: 0.8349 - val_acc: 0.7321\n",
            "Epoch 579/700\n",
            "504/504 [==============================] - 0s 379us/sample - loss: 0.2172 - acc: 0.9484 - val_loss: 0.8495 - val_acc: 0.7381\n",
            "Epoch 580/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.2261 - acc: 0.9385 - val_loss: 0.8397 - val_acc: 0.7381\n",
            "Epoch 581/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.2141 - acc: 0.9504 - val_loss: 0.8430 - val_acc: 0.7440\n",
            "Epoch 582/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.2170 - acc: 0.9643 - val_loss: 0.8347 - val_acc: 0.7381\n",
            "Epoch 583/700\n",
            "504/504 [==============================] - 0s 407us/sample - loss: 0.2093 - acc: 0.9623 - val_loss: 0.8410 - val_acc: 0.7321\n",
            "Epoch 584/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.2187 - acc: 0.9504 - val_loss: 0.8467 - val_acc: 0.7440\n",
            "Epoch 585/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.2141 - acc: 0.9583 - val_loss: 0.8430 - val_acc: 0.7202\n",
            "Epoch 586/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.2218 - acc: 0.9484 - val_loss: 0.8681 - val_acc: 0.7381\n",
            "Epoch 587/700\n",
            "504/504 [==============================] - 0s 416us/sample - loss: 0.2135 - acc: 0.9484 - val_loss: 0.9164 - val_acc: 0.7083\n",
            "Epoch 588/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.2330 - acc: 0.9365 - val_loss: 0.8697 - val_acc: 0.7440\n",
            "Epoch 589/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.2214 - acc: 0.9464 - val_loss: 0.8567 - val_acc: 0.7381\n",
            "Epoch 590/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.2092 - acc: 0.9643 - val_loss: 0.8572 - val_acc: 0.7143\n",
            "Epoch 591/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.2074 - acc: 0.9623 - val_loss: 0.8685 - val_acc: 0.7202\n",
            "Epoch 592/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.2080 - acc: 0.9484 - val_loss: 0.8802 - val_acc: 0.7262\n",
            "Epoch 593/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.2105 - acc: 0.9583 - val_loss: 0.8495 - val_acc: 0.7321\n",
            "Epoch 594/700\n",
            "504/504 [==============================] - 0s 386us/sample - loss: 0.2068 - acc: 0.9484 - val_loss: 0.8633 - val_acc: 0.7262\n",
            "Epoch 595/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.2104 - acc: 0.9524 - val_loss: 0.8585 - val_acc: 0.7202\n",
            "Epoch 596/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.2075 - acc: 0.9504 - val_loss: 0.8492 - val_acc: 0.7381\n",
            "Epoch 597/700\n",
            "504/504 [==============================] - 0s 410us/sample - loss: 0.2106 - acc: 0.9444 - val_loss: 0.8463 - val_acc: 0.7381\n",
            "Epoch 598/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.1923 - acc: 0.9603 - val_loss: 0.8844 - val_acc: 0.7440\n",
            "Epoch 599/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.2045 - acc: 0.9544 - val_loss: 0.8467 - val_acc: 0.7262\n",
            "Epoch 600/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.2096 - acc: 0.9623 - val_loss: 0.8568 - val_acc: 0.7321\n",
            "Epoch 601/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.1952 - acc: 0.9643 - val_loss: 0.8772 - val_acc: 0.7143\n",
            "Epoch 602/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.2086 - acc: 0.9583 - val_loss: 0.8442 - val_acc: 0.7381\n",
            "Epoch 603/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.2029 - acc: 0.9524 - val_loss: 0.8474 - val_acc: 0.7262\n",
            "Epoch 604/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.1971 - acc: 0.9663 - val_loss: 0.8984 - val_acc: 0.7083\n",
            "Epoch 605/700\n",
            "504/504 [==============================] - 0s 390us/sample - loss: 0.2019 - acc: 0.9603 - val_loss: 0.8691 - val_acc: 0.7202\n",
            "Epoch 606/700\n",
            "504/504 [==============================] - 0s 386us/sample - loss: 0.1931 - acc: 0.9683 - val_loss: 0.8650 - val_acc: 0.7321\n",
            "Epoch 607/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.1967 - acc: 0.9524 - val_loss: 0.8586 - val_acc: 0.7321\n",
            "Epoch 608/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.1890 - acc: 0.9683 - val_loss: 0.8610 - val_acc: 0.7321\n",
            "Epoch 609/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.2021 - acc: 0.9583 - val_loss: 0.8583 - val_acc: 0.7321\n",
            "Epoch 610/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.1915 - acc: 0.9603 - val_loss: 0.8842 - val_acc: 0.7321\n",
            "Epoch 611/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.2039 - acc: 0.9524 - val_loss: 0.8708 - val_acc: 0.7321\n",
            "Epoch 612/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.2045 - acc: 0.9563 - val_loss: 0.8750 - val_acc: 0.7262\n",
            "Epoch 613/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.1952 - acc: 0.9623 - val_loss: 0.8587 - val_acc: 0.7381\n",
            "Epoch 614/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.1942 - acc: 0.9643 - val_loss: 0.8629 - val_acc: 0.7381\n",
            "Epoch 615/700\n",
            "504/504 [==============================] - 0s 384us/sample - loss: 0.1892 - acc: 0.9583 - val_loss: 0.8472 - val_acc: 0.7321\n",
            "Epoch 616/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.1855 - acc: 0.9663 - val_loss: 0.8624 - val_acc: 0.7321\n",
            "Epoch 617/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.1961 - acc: 0.9563 - val_loss: 0.8907 - val_acc: 0.7321\n",
            "Epoch 618/700\n",
            "504/504 [==============================] - 0s 401us/sample - loss: 0.1984 - acc: 0.9643 - val_loss: 0.8647 - val_acc: 0.7321\n",
            "Epoch 619/700\n",
            "504/504 [==============================] - 0s 383us/sample - loss: 0.1849 - acc: 0.9643 - val_loss: 0.8760 - val_acc: 0.7440\n",
            "Epoch 620/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.1978 - acc: 0.9504 - val_loss: 0.8969 - val_acc: 0.7321\n",
            "Epoch 621/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.1940 - acc: 0.9643 - val_loss: 0.8706 - val_acc: 0.7381\n",
            "Epoch 622/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.1821 - acc: 0.9603 - val_loss: 0.8672 - val_acc: 0.7321\n",
            "Epoch 623/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.1982 - acc: 0.9544 - val_loss: 0.8562 - val_acc: 0.7262\n",
            "Epoch 624/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.1855 - acc: 0.9643 - val_loss: 0.8614 - val_acc: 0.7321\n",
            "Epoch 625/700\n",
            "504/504 [==============================] - 0s 381us/sample - loss: 0.1854 - acc: 0.9643 - val_loss: 0.8775 - val_acc: 0.7381\n",
            "Epoch 626/700\n",
            "504/504 [==============================] - 0s 417us/sample - loss: 0.1782 - acc: 0.9762 - val_loss: 0.8697 - val_acc: 0.7381\n",
            "Epoch 627/700\n",
            "504/504 [==============================] - 0s 380us/sample - loss: 0.1856 - acc: 0.9603 - val_loss: 0.8618 - val_acc: 0.7321\n",
            "Epoch 628/700\n",
            "504/504 [==============================] - 0s 415us/sample - loss: 0.1838 - acc: 0.9663 - val_loss: 0.8757 - val_acc: 0.7321\n",
            "Epoch 629/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.1814 - acc: 0.9643 - val_loss: 0.8825 - val_acc: 0.7321\n",
            "Epoch 630/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.1786 - acc: 0.9722 - val_loss: 0.8791 - val_acc: 0.7321\n",
            "Epoch 631/700\n",
            "504/504 [==============================] - 0s 381us/sample - loss: 0.1802 - acc: 0.9782 - val_loss: 0.8643 - val_acc: 0.7440\n",
            "Epoch 632/700\n",
            "504/504 [==============================] - 0s 382us/sample - loss: 0.1875 - acc: 0.9643 - val_loss: 0.8569 - val_acc: 0.7321\n",
            "Epoch 633/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.1892 - acc: 0.9524 - val_loss: 0.9029 - val_acc: 0.7202\n",
            "Epoch 634/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.1833 - acc: 0.9702 - val_loss: 0.8760 - val_acc: 0.7321\n",
            "Epoch 635/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.1813 - acc: 0.9623 - val_loss: 0.9047 - val_acc: 0.7143\n",
            "Epoch 636/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.1818 - acc: 0.9683 - val_loss: 0.9005 - val_acc: 0.7321\n",
            "Epoch 637/700\n",
            "504/504 [==============================] - 0s 382us/sample - loss: 0.1786 - acc: 0.9722 - val_loss: 0.8636 - val_acc: 0.7440\n",
            "Epoch 638/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.1782 - acc: 0.9683 - val_loss: 0.8951 - val_acc: 0.7440\n",
            "Epoch 639/700\n",
            "504/504 [==============================] - 0s 389us/sample - loss: 0.1723 - acc: 0.9603 - val_loss: 0.9366 - val_acc: 0.7143\n",
            "Epoch 640/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.1901 - acc: 0.9603 - val_loss: 0.8744 - val_acc: 0.7321\n",
            "Epoch 641/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.1814 - acc: 0.9603 - val_loss: 0.8785 - val_acc: 0.7440\n",
            "Epoch 642/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.1811 - acc: 0.9663 - val_loss: 0.8924 - val_acc: 0.7381\n",
            "Epoch 643/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.1758 - acc: 0.9643 - val_loss: 0.8914 - val_acc: 0.7321\n",
            "Epoch 644/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.1810 - acc: 0.9643 - val_loss: 0.8813 - val_acc: 0.7440\n",
            "Epoch 645/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.1740 - acc: 0.9702 - val_loss: 0.8983 - val_acc: 0.7321\n",
            "Epoch 646/700\n",
            "504/504 [==============================] - 0s 385us/sample - loss: 0.1788 - acc: 0.9663 - val_loss: 0.8687 - val_acc: 0.7262\n",
            "Epoch 647/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.1703 - acc: 0.9722 - val_loss: 0.8691 - val_acc: 0.7381\n",
            "Epoch 648/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.1672 - acc: 0.9742 - val_loss: 0.8719 - val_acc: 0.7321\n",
            "Epoch 649/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.1722 - acc: 0.9603 - val_loss: 0.8595 - val_acc: 0.7381\n",
            "Epoch 650/700\n",
            "504/504 [==============================] - 0s 382us/sample - loss: 0.1596 - acc: 0.9742 - val_loss: 0.8720 - val_acc: 0.7440\n",
            "Epoch 651/700\n",
            "504/504 [==============================] - 0s 396us/sample - loss: 0.1698 - acc: 0.9643 - val_loss: 0.8691 - val_acc: 0.7262\n",
            "Epoch 652/700\n",
            "504/504 [==============================] - 0s 394us/sample - loss: 0.1738 - acc: 0.9524 - val_loss: 0.8773 - val_acc: 0.7381\n",
            "Epoch 653/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.1634 - acc: 0.9742 - val_loss: 0.8841 - val_acc: 0.7440\n",
            "Epoch 654/700\n",
            "504/504 [==============================] - 0s 407us/sample - loss: 0.1699 - acc: 0.9722 - val_loss: 0.8738 - val_acc: 0.7440\n",
            "Epoch 655/700\n",
            "504/504 [==============================] - 0s 400us/sample - loss: 0.1662 - acc: 0.9762 - val_loss: 0.8910 - val_acc: 0.7262\n",
            "Epoch 656/700\n",
            "504/504 [==============================] - 0s 398us/sample - loss: 0.1654 - acc: 0.9702 - val_loss: 0.8708 - val_acc: 0.7440\n",
            "Epoch 657/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.1483 - acc: 0.9881 - val_loss: 0.8753 - val_acc: 0.7500\n",
            "Epoch 658/700\n",
            "504/504 [==============================] - 0s 406us/sample - loss: 0.1578 - acc: 0.9722 - val_loss: 0.9030 - val_acc: 0.7381\n",
            "Epoch 659/700\n",
            "504/504 [==============================] - 0s 386us/sample - loss: 0.1640 - acc: 0.9663 - val_loss: 0.8800 - val_acc: 0.7440\n",
            "Epoch 660/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.1607 - acc: 0.9702 - val_loss: 0.8903 - val_acc: 0.7381\n",
            "Epoch 661/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.1624 - acc: 0.9683 - val_loss: 0.8974 - val_acc: 0.7500\n",
            "Epoch 662/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.1589 - acc: 0.9702 - val_loss: 0.8891 - val_acc: 0.7440\n",
            "Epoch 663/700\n",
            "504/504 [==============================] - 0s 420us/sample - loss: 0.1593 - acc: 0.9742 - val_loss: 0.8916 - val_acc: 0.7440\n",
            "Epoch 664/700\n",
            "504/504 [==============================] - 0s 381us/sample - loss: 0.1571 - acc: 0.9821 - val_loss: 0.8920 - val_acc: 0.7321\n",
            "Epoch 665/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.1571 - acc: 0.9782 - val_loss: 0.8847 - val_acc: 0.7381\n",
            "Epoch 666/700\n",
            "504/504 [==============================] - 0s 386us/sample - loss: 0.1557 - acc: 0.9722 - val_loss: 0.8830 - val_acc: 0.7500\n",
            "Epoch 667/700\n",
            "504/504 [==============================] - 0s 382us/sample - loss: 0.1640 - acc: 0.9623 - val_loss: 0.8974 - val_acc: 0.7381\n",
            "Epoch 668/700\n",
            "504/504 [==============================] - 0s 424us/sample - loss: 0.1537 - acc: 0.9702 - val_loss: 0.8860 - val_acc: 0.7560\n",
            "Epoch 669/700\n",
            "504/504 [==============================] - 0s 377us/sample - loss: 0.1604 - acc: 0.9762 - val_loss: 0.9273 - val_acc: 0.7143\n",
            "Epoch 670/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.1550 - acc: 0.9782 - val_loss: 0.8863 - val_acc: 0.7440\n",
            "Epoch 671/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.1572 - acc: 0.9722 - val_loss: 0.9154 - val_acc: 0.7321\n",
            "Epoch 672/700\n",
            "504/504 [==============================] - 0s 383us/sample - loss: 0.1556 - acc: 0.9722 - val_loss: 0.8818 - val_acc: 0.7381\n",
            "Epoch 673/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.1648 - acc: 0.9742 - val_loss: 0.8714 - val_acc: 0.7440\n",
            "Epoch 674/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.1609 - acc: 0.9742 - val_loss: 0.8829 - val_acc: 0.7500\n",
            "Epoch 675/700\n",
            "504/504 [==============================] - 0s 380us/sample - loss: 0.1555 - acc: 0.9762 - val_loss: 0.8841 - val_acc: 0.7321\n",
            "Epoch 676/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.1534 - acc: 0.9742 - val_loss: 0.8871 - val_acc: 0.7560\n",
            "Epoch 677/700\n",
            "504/504 [==============================] - 0s 388us/sample - loss: 0.1505 - acc: 0.9683 - val_loss: 0.8736 - val_acc: 0.7500\n",
            "Epoch 678/700\n",
            "504/504 [==============================] - 0s 412us/sample - loss: 0.1479 - acc: 0.9802 - val_loss: 0.8774 - val_acc: 0.7440\n",
            "Epoch 679/700\n",
            "504/504 [==============================] - 0s 376us/sample - loss: 0.1629 - acc: 0.9643 - val_loss: 0.8830 - val_acc: 0.7381\n",
            "Epoch 680/700\n",
            "504/504 [==============================] - 0s 376us/sample - loss: 0.1462 - acc: 0.9702 - val_loss: 0.8935 - val_acc: 0.7321\n",
            "Epoch 681/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.1463 - acc: 0.9802 - val_loss: 0.8953 - val_acc: 0.7381\n",
            "Epoch 682/700\n",
            "504/504 [==============================] - 0s 384us/sample - loss: 0.1502 - acc: 0.9663 - val_loss: 0.8966 - val_acc: 0.7381\n",
            "Epoch 683/700\n",
            "504/504 [==============================] - 0s 410us/sample - loss: 0.1422 - acc: 0.9722 - val_loss: 0.8964 - val_acc: 0.7381\n",
            "Epoch 684/700\n",
            "504/504 [==============================] - 0s 392us/sample - loss: 0.1426 - acc: 0.9802 - val_loss: 0.9017 - val_acc: 0.7381\n",
            "Epoch 685/700\n",
            "504/504 [==============================] - 0s 387us/sample - loss: 0.1378 - acc: 0.9821 - val_loss: 0.8930 - val_acc: 0.7381\n",
            "Epoch 686/700\n",
            "504/504 [==============================] - 0s 384us/sample - loss: 0.1514 - acc: 0.9802 - val_loss: 0.9145 - val_acc: 0.7440\n",
            "Epoch 687/700\n",
            "504/504 [==============================] - 0s 404us/sample - loss: 0.1524 - acc: 0.9643 - val_loss: 0.8889 - val_acc: 0.7500\n",
            "Epoch 688/700\n",
            "504/504 [==============================] - 0s 403us/sample - loss: 0.1450 - acc: 0.9782 - val_loss: 0.8913 - val_acc: 0.7381\n",
            "Epoch 689/700\n",
            "504/504 [==============================] - 0s 381us/sample - loss: 0.1493 - acc: 0.9762 - val_loss: 0.8916 - val_acc: 0.7500\n",
            "Epoch 690/700\n",
            "504/504 [==============================] - 0s 386us/sample - loss: 0.1455 - acc: 0.9802 - val_loss: 0.9175 - val_acc: 0.7560\n",
            "Epoch 691/700\n",
            "504/504 [==============================] - 0s 393us/sample - loss: 0.1550 - acc: 0.9623 - val_loss: 0.9078 - val_acc: 0.7381\n",
            "Epoch 692/700\n",
            "504/504 [==============================] - 0s 379us/sample - loss: 0.1403 - acc: 0.9802 - val_loss: 0.8996 - val_acc: 0.7381\n",
            "Epoch 693/700\n",
            "504/504 [==============================] - 0s 391us/sample - loss: 0.1441 - acc: 0.9782 - val_loss: 0.9076 - val_acc: 0.7560\n",
            "Epoch 694/700\n",
            "504/504 [==============================] - 0s 414us/sample - loss: 0.1430 - acc: 0.9702 - val_loss: 0.9375 - val_acc: 0.7321\n",
            "Epoch 695/700\n",
            "504/504 [==============================] - 0s 395us/sample - loss: 0.1513 - acc: 0.9742 - val_loss: 0.9050 - val_acc: 0.7619\n",
            "Epoch 696/700\n",
            "504/504 [==============================] - 0s 386us/sample - loss: 0.1345 - acc: 0.9802 - val_loss: 0.9131 - val_acc: 0.7381\n",
            "Epoch 697/700\n",
            "504/504 [==============================] - 0s 399us/sample - loss: 0.1424 - acc: 0.9782 - val_loss: 0.9314 - val_acc: 0.7500\n",
            "Epoch 698/700\n",
            "504/504 [==============================] - 0s 386us/sample - loss: 0.1312 - acc: 0.9861 - val_loss: 0.9240 - val_acc: 0.7440\n",
            "Epoch 699/700\n",
            "504/504 [==============================] - 0s 397us/sample - loss: 0.1434 - acc: 0.9802 - val_loss: 0.9097 - val_acc: 0.7560\n",
            "Epoch 700/700\n",
            "504/504 [==============================] - 0s 402us/sample - loss: 0.1409 - acc: 0.9782 - val_loss: 0.9138 - val_acc: 0.7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJo6XBT9tklK",
        "colab_type": "code",
        "outputId": "21495aa7-c90a-4716-e9d1-d234bfc8771d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWYIwxhjj1/8Dq3RUctA29gUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-ehpIYq9BUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/drive/My Drive/Saved_models/model.ravdess.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}